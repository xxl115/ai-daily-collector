---
title: "The crucial first step for designing a successful enterprise AI system"
url: "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/"
source: "MIT Technology Review"
date: "2026-02-03"
---

# The crucial first step for designing a successful enterprise AI system

**来源**: [MIT Technology Review](https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)

## 原文内容

Title: What we’ve been getting wrong about AI’s truth crisis

URL Source: http://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/

Published Time: 2026-02-02T13:09:57-05:00

Markdown Content:
What we’ve been getting wrong about AI’s truth crisis | MIT Technology Review
===============

[Skip to Content](http://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/#content)

[MIT Technology Review](https://www.technologyreview.com/)

*   [Featured](http://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)
*   [Topics](http://www.technologyreview.com/all-topics)
*   [Newsletters](http://www.technologyreview.com/newsletter-preferences)
*   [Events](https://events.technologyreview.com/)
*   [Audio](http://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)

[Sign in](http://www.technologyreview.com/login&redirectTo=/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)

[Subscribe & Save 25%](http://www.technologyreview.com/subscribe?itm_source=nav-button&itm_medium=onsite&itm_campaign=subscribe-BAU)

[MIT Technology Review](https://www.technologyreview.com/)

*   [Featured](http://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)
*   [Topics](http://www.technologyreview.com/all-topics)
*   [Newsletters](http://www.technologyreview.com/newsletter-preferences)
*   [Events](https://events.technologyreview.com/)
*   [Audio](http://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)

[Sign in](http://www.technologyreview.com/login&redirectTo=/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)

[Subscribe & Save 25%](http://www.technologyreview.com/subscribe?itm_source=nav-button&itm_medium=onsite&itm_campaign=subscribe-BAU)

[Artificial intelligence](https://www.technologyreview.com/topic/artificial-intelligence/)

What we’ve been getting wrong about AI’s truth crisis
=====================================================

Even when content is revealed to be manipulated, it still shapes our beliefs. The defenders of truth are hopelessly behind.

By 
*   [James O'Donnell archive page](https://www.technologyreview.com/author/james-odonnell/)

February 2, 2026

![Image 1: Kristi Noem seen pixelated through the viewfinder of a camera](https://wp.technologyreview.com/wp-content/uploads/2026/02/GettyImages-2255281268.jpg)

Michael M. Santiago/Getty Images

_This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,[sign up here](https://forms.technologyreview.com/newsletters/ai-demystified-the-algorithm/)._

What would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even when we catch the lie, and erodes societal trust in the process—is now here? A story I published last week pushed me over the edge. It also made me realize that the tools we were sold as a cure for this crisis are failing miserably.

On Thursday, I [reported](https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/) the first confirmation that the US Department of Homeland Security, which houses immigration agencies, is using AI video generators from Google and Adobe to make content that it shares with the public. The news comes as immigration agencies have flooded social media with content to support President Trump's mass deportation agenda—some of which appears to be made with AI (like a [video](https://x.com/DHSgov/status/2002424827798585786) about “Christmas after mass deportations”).

But I received two types of reactions from readers that may explain just as much about the epistemic crisis we’re in.

One was from people who weren’t surprised, because on January 22 the White House had posted a [digitally altered](https://www.theguardian.com/us-news/2026/jan/22/white-house-ice-protest-arrest-altered-image) photo of a woman arrested at an ICE protest, one that made her appear hysterical and in tears. Kaelan Dorr, the White House’s deputy communications director, did not respond to questions about whether the White House altered the photo but [wrote](https://x.com/Kaelan47/status/2014410500096856358?s=20), “The memes will continue.”

The second was from readers who saw no point in reporting that DHS was using AI to edit content shared with the public, because news outlets were apparently doing the same. They pointed to the fact that the news network MS Now (formerly MSNBC) shared an image of Alex Pretti that was AI-edited and appeared to make him look more handsome, a fact that led to many viral clips this week, including one from Joe Rogan’s podcast. Fight fire with fire, in other words? A spokesperson for MS Now [told Snopes](https://www.snopes.com/fact-check/alex-pretti-photo-ai-msnbc/) that the news outlet aired the image without knowing it was edited.

There is no reason to collapse these two cases of altered content into the same category, or to read them as evidence that truth no longer matters. One involved the US government sharing a clearly altered photo with the public and declining to answer whether it was intentionally manipulated; the other involved a news outlet airing a photo it [should have known](https://perma.cc/JB3J-57QN) was altered but taking some steps to disclose the mistake.

What these reactions reveal instead is a flaw in how we were collectively preparing for this moment. Warnings about the AI truth crisis revolved around a core thesis: that not being able to tell what is real will destroy us, so we need tools to independently verify the truth. My two grim takeaways are that these tools are failing, and that while vetting the truth remains essential, it is no longer capable on its own of producing the societal trust we were promised.

Related Story
-------------

[](https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/)[Inside the marketplace powering bespoke AI deepfakes of real women](https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/)[Read next](https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/)

For example, there was plenty of hype in 2024 about the Content Authenticity Initiative, cofounded by Adobe and adopted by major tech companies, which would attach labels to content disclosing when it was made, by whom, and whether AI was involved. But Adobe applies automatic labels only when the content is wholly AI-generated. Otherwise the labels are opt-in on the part of the creator.

And platforms like X, where the altered arrest photo was posted, can strip content of such labels anyway (a note that the photo was altered was [added](https://x.com/WhiteHouse/status/2014365986388951194/photo/1) by users). Platforms can also simply not choose to show the label; indeed, when Adobe launched the initiative, it [noted](https://blog.adobe.com/en/publish/2024/09/18/authenticity-age-ai-growing-content-credentials-momentum-across-social-media-platforms-ai-companies-rising-consumer-awareness) that the Pentagon's website for sharing official images, DVIDS, would display the labels to prove authenticity, but a review of the website today shows no such labels.

Noticing how much traction the White House’s photo got even after it was shown to be AI-altered, I was struck by the findings of a very relevant new [paper](https://www.nature.com/articles/s44271-025-00381-9) published in the journal _Communications Psychology_. In the study, participants watched a deepfake “confession” to a crime, and the researchers found that even when they were told explicitly that the evidence was fake, participants relied on it when judging an individual’s guilt.In other words, even when people learn that the content they’re looking at is entirely fake, they remain emotionally swayed by it.

“Transparency helps, but it isn’t enough on its own,” the disinformation expert Christopher Nehring [wrote](https://www.linkedin.com/posts/christopher-n-423b06257_influence-of-deepfakes-activity-7422200374591361043-Fp5C?utm_source=share&utm_medium=member_desktop&rcm=ACoAADzDcuoBK3BxlTOFUM8kwVIgx8nHdh4DhwY) recently about the study’s findings. “We have to develop a new masterplan of what to do about deepfakes.”

AI tools to generate and edit content are getting more advanced, easier to operate, and cheaper to run—all reasons why the US government is increasingly paying to use them. We were well warned of this, but we responded by preparing for a world in which the main danger was confusion. What we’re entering instead is a world in which influence survives exposure, doubt is easily weaponized, and establishing the truth does not serve as a reset button. And the defenders of truth are already trailing way behind.

_Update: This story was updated on February 2 with details about how Adobe applies its content authenticity labels._

hide

### by[James O'Donnell](https://www.technologyreview.com/author/james-odonnell/)

### Share

*   [Share story on linkedin](https://www.linkedin.com/shareArticle/?url=https%3A%2F%2Fwww.technologyreview.com%2F2026%2F02%2F02%2F1132068%2Fwhat-weve-been-getting-wrong-about-ais-truth-crisis%2F&title=What%20we%E2%80%99ve%20been%20getting%20wrong%20about%20AI%E2%80%99s%20truth%20crisis&summary=This%20story%20originally%20appeared%20in%20The%20Algorithm%2C%20our%20weekly%20newsletter%20on%20AI.%20To%20get%20stories%20like%20this%20in%20your%20inbox%20first%2C%C2%A0sign%20up%20here.%20What%20would%20it%20take%20to%20convince%20you%20that%20the%20era%20of%20truth%20decay%20we%20were%20long%20warned%20about%E2%80%94where%20AI%20content%20dupes%20us%2C%20shapes%20our%20beliefs%20even%20when%20we%20catch%20the%20lie%2C%20and%E2%80%A6)
*   [Share story on facebook](https://www.facebook.com/sharer.php/?u=https%3A%2F%2Fwww.technologyreview.com%2F2026%2F02%2F02%2F1132068%2Fwhat-weve-been-getting-wrong-about-ais-truth-crisis%2F)
*   [](https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/)
*   [Share story on email](mailto:?subject=What%20we%E2%80%99ve%20been%20getting%20wrong%20about%20AI%E2%80%99s%20truth%20crisis&body=https%3A%2F%2Fwww.technologyreview.com%2F2026%2F02%2F02%2F1132068%2Fwhat-weve-been-getting-wrong-about-ais-truth-crisis%2F)

*       
*   
### Popular

    1.   [10 Breakthrough Technologies 2026](https://www.technologyreview.com/2026/01/12/1130697/10-breakthrough-technologies-2026/)[Amy Nordrum](https://www.technologyreview.com/author/amy-nordrum/)
    2.   [The great AI hype correction of 2025](https://www.technologyreview.com/2025/12/15/1129174/the-great-ai-hype-correction-of-2025/)[Will Douglas Heaven](https://www.technologyreview.com/author/will-douglas-heaven/)
    3.   [The 8 worst technology flops of 2025](https://www.technologyreview.com/2025/12/18/1130106/the-8-worst-technology-flops-of-2025/)[Antonio Regalado](https://www.technologyreview.com/author/antonio-regalado/)
    4.   [China figured out how to sell EVs. Now it has to deal with their aging batteries.](https://www.technologyreview.com/2025/12/18/1130148/china-ev-battery-recycle/)[Caiwei Chen](https://www.technologyreview.com/author/caiwei-chen/)

### Deep Dive

### Artificial intelligence

[### The great AI hype correction of 2025](https://www.technologyreview.com/2025/12/15/1129174/the-great-ai-hype-correction-of-2025/)

Four ways to think about this year's reckoning.

By 
*   [Will Douglas Heaven archive page](https://www.technologyreview.com/author/will-douglas-heaven/)

[### Meet the new biologists treating LLMs like aliens](https://www.technologyreview.com/2026/01/12/1129782/ai-large-language-models-biology-alien-autopsy/)

By studying large language models as if they were living things instead of computer programs, scientists are discovering some of their secrets for the first time.

By 
*   [Will Douglas Heaven archive page](https://www.technologyreview.com/author/will-douglas-heaven/)

[### Yann LeCun’s new venture is a contrarian bet against large language models](https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/)

In an exclusive interview, the AI pioneer shares his plans for his new Paris-based company, AMI Labs.

By 
*   [Caiwei Chen archive page](https://www.technologyreview.com/author/caiwei-chen/)

[### What’s next for AI in 2026](https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/)

Our AI writers make their big bets for the coming year—here are five hot trends to watch.

By 
*   [Rhiannon Williams archive page](https://www.technologyreview.com/author/rhiannon-williams/)
*   [Will Douglas Heaven archive page](https://www.technologyreview.com/author/will-douglas-heaven/)
*   [Caiwei Chen archive page](https://www.technologyreview.com/author/caiwei-chen/)
*   [James O'Donnell archive page](https://www.technologyreview.com/author/james-odonnell/)
*   [Michelle Kim archive page](https://www.technologyreview.com/author/michelle-kim/)

### Stay connected

Illustration by Rose Wong

Get the latest updates from

MIT Technology Review
--------------------------------------------------

Discover special offers, top stories, upcoming events, and more.

Enter your email

[Privacy Policy](http://www.technologyreview.com/privacy/) 

Thank you for submitting your email!

[Explore more newsletters](http://www.technologyreview.com/newsletter-preferences?email_address=undefined)

It looks like something went wrong.

We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at [customer-service@technologyreview.com](mailto:customer-service@technologyreview.com) with a list of newsletters you’d like to receive.

### The latest iteration of a legacy

Founded at the Massachusetts Institute of Technology in 1899, MIT Technology Review is a world-renowned, independent media company whose insight, analysis, reviews, interviews and live events explain the newest technologies and their commercial, social and political impact.

[READ ABOUT OUR HISTORY](https://www.technologyreview.com/supertopic/about-mit-technology-review/)

### Advertise with MIT Technology Review

Elevate your brand to the forefront of conversation around emerging technologies that are radically transforming business. From event sponsorships to custom content to visually arresting video storytelling, advertising with MIT Technology Review creates opportunities for your brand to resonate with an unmatched audience of technology and business elite.

[ADVERTISE WITH US](https://mediakit.technologyreview.com/)

© 2026 MIT Technology Review

*   ### About

    *   [About us](https://www.technologyreview.com/supertopic/about-mit-technology-review/)
    *   [Careers](http://www.technologyreview.com/open-positions/)
    *   [Custom content](http://www.technologyreview.com/custom-content)
    *   [Advertise with us](https://mediakit.technologyreview.com/)
    *   [International Editions](https://www.technologyreview.com/international-editions/)
    *   [Republishing](https://www.technologyreview.com/republishing/)
    *   [MIT Alumni News](http://www.technologyreview.com/mit-news)

*   ### Help

    *   [Help & FAQ](https://www.technologyreview.com/help/)
    *   [My subscription](https://subscriptions.technologyreview.com/loading.do?omedasite=MITTR_LAND)
    *   [Editorial guidelines](https://www.technologyreview.com/editorial-guidelines/)
    *   [Privacy policy](https://www.technologyreview.com/privacy/)
    *   [Terms of Service](https://www.technologyreview.com/terms-of-service/)
    *   [Write for us](https://www.technologyreview.com/how-to-pitch-mit-technology-review/)
    *   [Contact us](https://www.technologyreview.com/help#contact-us)

*   [linkedin opens in a new window](https://www.linkedin.com/company/mit-technology-review)
*   [instagram opens in a new window](https://www.instagram.com/technologyreview/)
*   [reddit opens in a new window](https://www.reddit.com/user/techreview/)
*   [facebook opens in a new window](https://www.facebook.com/technologyreview/)
*   [rss opens in a new window](https://www.technologyreview.com/feed/)

Cookie Policy
-------------

We use cookies to give you a more personalized browsing experience and analyze site traffic.[See our cookie policy](https://www.technologyreview.com/cookies/)

Accept all cookies

Cookies settings

Privacy Preference Center
-------------------------

When you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer. 

[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)

Allow all
### Manage Consent Preferences

#### Strictly Necessary Cookies

Always Active

These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.

#### Functional Cookies

- [x] Functional Cookies 

These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.

#### Performance Cookies

- [x] Performance Cookies 

These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.

#### Targeting Cookies

- [x] Targeting Cookies 

These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.

### Performance Cookies

Clear

- [x] checkbox label label

Apply Cancel

Consent Leg.Interest

- [x] checkbox label label

- [x] checkbox label label

- [x] checkbox label label

Reject all Confirm my choices

[![Image 4: Powered by Onetrust](https://cdn.cookielaw.org/logos/static/powered_by_logo.svg)](https://www.onetrust.com/products/cookie-consent/)

![Image 5](https://bat.bing.com/action/0?ti=16002556&tm=gtm002&Ver=2&mid=939755f0-63c8-468d-a3a4-79fd852f4e5c&bo=1&sid=d6c727a0009211f1a4c25f5a65e7d03a&vid=d6c74390009211f1b8597be8ad1faa91&vids=1&msclkid=N&pi=918639831&lg=en-US&sw=800&sh=600&sc=24&tl=What%20we%E2%80%99ve%20been%20getting%20wrong%20about%20AI%E2%80%99s%20truth%20crisis%20%7C%20MIT%20Technology%20Review&p=https%3A%2F%2Fwww.technologyreview.com%2F2026%2F02%2F02%2F1132068%2Fwhat-weve-been-getting-wrong-about-ais-truth-crisis%2F&r=&lt=1223&evt=pageLoad&sv=2&cdb=AQER&rn=445636)

![Image 6](https://t.co/1/i/adsct?bci=4&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=3&event=%7B%7D&event_id=bf78be61-ffe4-48c8-8893-2f22ad1d6159&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=2f3d12c8-5f23-4ce0-9e9d-9b4b8a93480f&pt=What%20we%E2%80%99ve%20been%20getting%20wrong%20about%20AI%E2%80%99s%20truth%20crisis%20%7C%20MIT%20Technology%20Review&tw_document_href=https%3A%2F%2Fwww.technologyreview.com%2F2026%2F02%2F02%2F1132068%2Fwhat-weve-been-getting-wrong-about-ais-truth-crisis%2F&tw_iframe_status=0&txn_id=nuwy6&type=javascript&version=2.3.35)![Image 7](https://analytics.twitter.com/1/i/adsct?bci=4&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=3&event=%7B%7D&event_id=bf78be61-ffe4-48c8-8893-2f22ad1d6159&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=2f3d12c8-5f23-4ce0-9e9d-9b4b8a93480f&pt=What%20we%E2%80%99ve%20been%20getting%20wrong%20about%20AI%E2%80%99s%20truth%20crisis%20%7C%20MIT%20Technology%20Review&tw_document_href=https%3A%2F%2Fwww.technologyreview.com%2F2026%2F02%2F02%2F1132068%2Fwhat-weve-been-getting-wrong-about-ais-truth-crisis%2F&tw_iframe_status=0&txn_id=nuwy6&type=javascript&version=2.3.35)

---
*自动采集于 2026-02-03*
