---
title: "Bruce Schneier: AI and the scaling of betrayal"
url: "https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html"
source: "Hacker News"
date: "2026-02-03"
score: "50"
author: "insuranceguru"
---

# Bruce Schneier: AI and the scaling of betrayal

**来源**: [Hacker News](https://news.ycombinator.com/item?id=46877075) | **评分**: 50 | **作者**: @insuranceguru

## 原文内容

Title: AI and Trust

URL Source: http://www.schneier.com/blog/archives/2023/12/ai-and-trust.html

Published Time: 2023-12-04T12:05:33+00:00

Markdown Content:
AI and Trust - Schneier on Security
===============

[Schneier on Security](https://www.schneier.com/)
=================================================

[Menu](http://www.schneier.com/blog/archives/2023/12/ai-and-trust.html#)

*   [Blog](https://www.schneier.com/)
*   [Newsletter](https://www.schneier.com/crypto-gram/)
*   [Books](https://www.schneier.com/books/)
*   [Essays](https://www.schneier.com/essays/)
*   [News](https://www.schneier.com/news/)
*   [Talks](https://www.schneier.com/talks/)
*   [Academic](https://www.schneier.com/academic/)
*   [About Me](https://www.schneier.com/blog/about/)

### Search

_Powered by [DuckDuckGo](https://duckduckgo.com/)_

Blog Essays Whole site 

### Subscribe

[![Image 1: Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Image 2: Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Image 3: Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Image 4: Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com/)[Blog](https://www.schneier.com/blog/archives/)

AI and Trust
------------

I trusted a lot today. I trusted my phone to wake me on time. I trusted Uber to arrange a taxi for me, and the driver to get me to the airport safely. I trusted thousands of other drivers on the road not to ram my car on the way. At the airport, I trusted ticket agents and maintenance engineers and everyone else who keeps airlines operating. And the pilot of the plane I flew in. And thousands of other people at the airport and on the plane, any of which could have attacked me. And all the people that prepared and served my breakfast, and the entire food supply chain—any of them could have poisoned me. When I landed here, I trusted thousands more people: at the airport, on the road, in this building, in this room. And that was all before 10:30 this morning.

Trust is essential to society. Humans as a species are trusting. We are all sitting here, mostly strangers, confident that nobody will attack us. If we were a roomful of chimpanzees, this would be impossible. We trust many thousands of times a day. Society can’t function without it. And that we don’t even think about it is a measure of how well it all works.

In this talk, I am going to make several arguments. One, that there are two different kinds of trust—interpersonal trust and social trust—and that we regularly confuse them. Two, that the confusion will increase with artificial intelligence. We will make a fundamental category error. We will think of AIs as friends when they’re really just services. Three, that the corporations controlling AI systems will take advantage of our confusion to take advantage of us. They will not be trustworthy. And four, that it is the role of government to create trust in society. And therefore, it is their role to create an environment for trustworthy AI. And that means regulation. Not regulating AI, but regulating the organizations that control and use AI.

Okay, so let’s back up and take that all a lot slower. Trust is a complicated concept, and the word is overloaded with many meanings. There’s personal and intimate trust. When we say that we trust a friend, it is less about their specific actions and more about them as a person. It’s a general reliance that they will behave in a trustworthy manner. We trust their intentions, and know that those intentions will inform their actions. Let’s call this “interpersonal trust.”

There’s also the less intimate, less personal trust. We might not know someone personally, or know their motivations—but we can trust their behavior. We don’t know whether or not someone wants to steal, but maybe we can trust that they won’t. It’s really more about reliability and predictability. We’ll call this “social trust.” It’s the ability to trust strangers.

Interpersonal trust and social trust are both essential in society today. This is how it works. We have mechanisms that induce people to behave in a trustworthy manner, both interpersonally and socially. This, in turn, allows others to be trusting. Which enables trust in society. And that keeps society functioning. The system isn’t perfect—there are always going to be untrustworthy people—but most of us being trustworthy most of the time is good enough.

I wrote about this in 2012 in a book called [_Liars and Outliers_](https://www.schneier.com/books/liars-and-outliers/). I wrote about four systems for enabling trust: our innate morals, concern about our reputations, the laws we live under, and security technologies that constrain our behavior. I wrote about how the first two are more informal than the last two. And how the last two scale better, and allow for larger and more complex societies. They enable cooperation amongst strangers.

What I didn’t appreciate is how different the first and last two are. Morals and reputation are person to person, based on human connection, mutual vulnerability, respect, integrity, generosity, and a lot of other things besides. These underpin interpersonal trust. Laws and security technologies are systems of trust that force us to act trustworthy. And they’re the basis of social trust.

Taxi driver used to be one of the country’s most dangerous professions. Uber changed that. I don’t know my Uber driver, but the rules and the technology lets us both be confident that neither of us will cheat or attack each other. We are both under constant surveillance and are competing for star rankings.

Lots of people write about the difference between living in a high-trust and a low-trust society. How reliability and predictability make everything easier. And what is lost when society doesn’t have those characteristics. Also, how societies move from high-trust to low-trust and vice versa. This is all about social trust.

That literature is important, but for this talk the critical point is that social trust scales better. You used to need a personal relationship with a banker to get a loan. Now it’s all done algorithmically, and you have many more options to choose from.

Social trust scales better, but embeds all sorts of bias and prejudice. That’s because, in order to scale, social trust has to be structured, system- and rule-oriented, and that’s where the bias gets embedded. And the system has to be mostly blinded to context, which removes flexibility.

But that scale is vital. In today’s society we regularly trust—or not—governments, corporations, brands, organizations, groups. It’s not so much that I trusted the particular pilot that flew my airplane, but instead the airline that puts well-trained and well-rested pilots in cockpits on schedule. I don’t trust the cooks and waitstaff at a restaurant, but the system of health codes they work under. I can’t even describe the banking system I trusted when I used an ATM this morning. Again, this confidence is no more than reliability and predictability.

Think of that restaurant again. Imagine that it’s a fast food restaurant, employing teenagers. The food is almost certainly safe—probably safer than in high-end restaurants—because of the corporate systems or reliability and predictability that is guiding their every behavior.

That’s the difference. You can ask a friend to deliver a package across town. Or you can pay the Post Office to do the same thing. The former is interpersonal trust, based on morals and reputation. You know your friend and how reliable they are. The second is a service, made possible by social trust. And to the extent that is a reliable and predictable service, it’s primarily based on laws and technologies. Both can get your package delivered, but only the second can become the global package delivery systems that is FedEx.

Because of how large and complex society has become, we have replaced many of the rituals and behaviors of interpersonal trust with security mechanisms that enforce reliability and predictability—social trust.

But because we use the same word for both, we regularly confuse them. And when we do that, we are making a category error.

And we do it all the time. With governments. With organizations. With systems of all kinds. And especially with corporations.

We might think of them as friends, when they are actually services. Corporations are not moral; they are precisely as immoral as the law and their reputations let them get away with.

So corporations regularly take advantage of their customers, mistreat their workers, pollute the environment, and lobby for changes in law so they can do even more of these things.

Both language and the laws make this an easy category error to make. We use the same grammar for people and corporations. We imagine that we have personal relationships with brands. We give corporations some of the same rights as people.

Corporations like that we make this category error—see, I just made it myself—because they profit when we think of them as friends. They use mascots and spokesmodels. They have social media accounts with personalities. They refer to themselves like they are people.

But they are not our friends. Corporations are not capable of having that kind of relationship.

We are about to make the same category error with AI. We’re going to think of them as our friends when they’re not.

A lot has been written about AIs as existential risk. The worry is that they will have a goal, and they will work to achieve it even if it harms humans in the process. You may have read about the “[paperclip maximizer](https://www.huffpost.com/entry/artificial-intelligence-oxford_n_5689858)“: an AI that has been programmed to make as many paper clips as possible, and ends up destroying the earth to achieve those ends. It’s a weird fear. Science fiction author Ted Chiang writes about it. Instead of solving all of humanity’s problems, or wandering off proving mathematical theorems that no one understands, the AI single-mindedly pursues the goal of maximizing production. Chiang’s point is that this is every corporation’s business plan. And that our fears of AI are basically fears of capitalism. Science fiction writer Charlie Stross takes this one step further, and calls corporations “[slow AI](https://www.antipope.org/charlie/blog-static/2018/01/dude-you-broke-the-future.html).” They are profit maximizing machines. And the most successful ones do whatever they can to achieve that singular goal.

And near-term AIs will be controlled by corporations. Which will use them towards that profit-maximizing goal. They won’t be our friends. At best, they’ll be useful services. More likely, they’ll spy on us and try to manipulate us.

This is nothing new. Surveillance is the business model of the Internet. Manipulation is the other business model of the Internet.

Your Google search results lead with URLs that someone paid to show to you. Your Facebook and Instagram feeds are filled with sponsored posts. Amazon searches return pages of products whose sellers paid for placement.

This is how the Internet works. Companies spy on us as we use their products and services. Data brokers buy that surveillance data from the smaller companies, and assemble detailed dossiers on us. Then they sell that information back to those and other companies, who combine it with data they collect in order to manipulate our behavior to serve their interests. At the expense of our own.

We use all of these services as if they are our agents, working on our behalf. In fact, they are double agents, also secretly working for their corporate owners. We trust them, but they are not trustworthy. They’re not friends; they’re services.

It’s going to be no different with AI. And the result will be much worse, for two reasons.

The first is that these AI systems will be more relational. We will be conversing with them, using natural language. As such, we will naturally ascribe human-like characteristics to them.

This relational nature will make it easier for those double agents to do their work. Did your chatbot recommend a particular airline or hotel because it’s truly the best deal, given your particular set of needs? Or because the AI company got a kickback from those providers? When you asked it to explain a political issue, did it bias that explanation towards the company’s position? Or towards the position of whichever political party gave it the most money? The conversational interface will help hide their agenda.

The second reason to be concerned is that these AIs will be more intimate. One of the promises of generative AI is a personal digital assistant. Acting as your advocate with others, and as a butler with you. This requires an intimacy greater than your search engine, email provider, cloud storage system, or phone. You’re going to want it with you 24/7, constantly training on everything you do. You will want it to know everything about you, so it can most effectively work on your behalf.

And it will help you in many ways. It will notice your moods and know what to suggest. It will anticipate your needs and work to satisfy them. It will be your therapist, life coach, and relationship counselor.

You will default to thinking of it as a friend. You will speak to it in natural language, and it will respond in kind. If it is a robot, it will look humanoid—or at least like an animal. It will interact with the whole of your existence, just like another person would.

The natural language interface is critical here. We are primed to think of others who speak our language as people. And we sometimes have trouble thinking of others who speak a different language that way. We make that category error with obvious non-people, like cartoon characters. We will naturally have a “theory of mind” about any AI we talk with.

More specifically, we tend to assume that something’s implementation is the same as its interface. That is, we assume that things are the same on the inside as they are on the surface. Humans are like that: we’re people through and through. A government is systemic and bureaucratic on the inside. You’re not going to mistake it for a person when you interact with it. But this is the category error we make with corporations. We sometimes mistake the organization for its spokesperson. AI has a fully relational interface—it talks like a person—but it has an equally fully systemic implementation. Like a corporation, but much more so. The implementation and interface are more divergent than anything we have encountered to date—by a lot.

And you will want to trust it. It will use your mannerisms and cultural references. It will have a convincing voice, a confident tone, and an authoritative manner. Its personality will be optimized to exactly what you like and respond to.

It will act trustworthy, but it will not be trustworthy. We won’t know how they are trained. We won’t know their secret instructions. We won’t know their biases, either accidental or deliberate.

We do know that they are built at enormous expense, mostly in secret, by profit-maximizing corporations for their own benefit.

It’s no accident that these corporate AIs have a human-like interface. There’s nothing inevitable about that. It’s a design choice. It could be designed to be less personal, less human-like, more obviously a service—like a search engine . The companies behind those AIs want you to make the friend/service category error. It will exploit your mistaking it for a friend. And you might not have any choice but to use it.

There is something we haven’t discussed when it comes to trust: power. Sometimes we have no choice but to trust someone or something because they are powerful. We are forced to trust the local police, because they’re the only law enforcement authority in town. We are forced to trust some corporations, because there aren’t viable alternatives. To be more precise, we have no choice but to entrust ourselves to them. We will be in this same position with AI. We will have no choice but to entrust ourselves to their decision-making.

The friend/service confusion will help mask this power differential. We will forget how powerful the corporation behind the AI is, because we will be fixated on the person we think the AI is.

So far, we have been talking about one particular failure that results from overly trusting AI. We can call it something like “hidden exploitation.” There are others. There’s outright fraud, where the AI is actually trying to steal stuff from you. There’s the more prosaic mistaken expertise, where you think the AI is more knowledgeable than it is because it acts confidently. There’s incompetency, where you believe that the AI can do something it can’t. There’s inconsistency, where you mistakenly expect the AI to be able to repeat its behaviors. And there’s illegality, where you mistakenly trust the AI to obey the law. There are probably more ways trusting an AI can fail.

All of this is a long-winded way of saying that we need trustworthy AI. AI whose behavior, limitations, and training are understood. AI whose biases are understood, and corrected for. AI whose goals are understood. That won’t secretly betray your trust to someone else.

The market will not provide this on its own. Corporations are profit maximizers, at the expense of society. And the incentives of surveillance capitalism are just too much to resist.

It’s government that provides the underlying mechanisms for the social trust essential to society. Think about contract law. Or laws about property, or laws protecting your personal safety. Or any of the health and safety codes that let you board a plane, eat at a restaurant, or buy a pharmaceutical without worry.

The more you can trust that your societal interactions are reliable and predictable, the more you can ignore their details. Places where governments don’t provide these things are not good places to live.

Government can do this with AI. We need AI transparency laws. When it is used. How it is trained. What biases and tendencies it has. We need laws regulating AI—and robotic—safety. When it is permitted to affect the world. We need laws that enforce the trustworthiness of AI. Which means the ability to recognize when those laws are being broken. And penalties sufficiently large to incent trustworthy behavior.

Many countries are contemplating AI safety and security laws—the EU is the furthest along—but I think they are making a critical mistake. They try to regulate the AIs and not the humans behind them.

AIs are not people; they don’t have agency. They are built by, trained by, and controlled by people. Mostly for-profit corporations. Any AI regulations should place restrictions on those people and corporations. Otherwise the regulations are making the same category error I’ve been talking about. At the end of the day, there is always a human responsible for whatever the AI’s behavior is. And it’s the human who needs to be responsible for what they do—and what their companies do. Regardless of whether it was due to humans, or AI, or a combination of both. Maybe that won’t be true forever, but it will be true in the near future. If we want trustworthy AI, we need to require trustworthy AI controllers.

We already have a system for this: fiduciaries. There are areas in society where trustworthiness is of paramount importance, even more than usual. Doctors, lawyers, accountants…these are all trusted agents. They need extraordinary access to our information and ourselves to do their jobs, and so they have additional legal responsibilities to act in our best interests. They have fiduciary responsibility to their clients.

We need the same sort of thing for our data. The idea of a data fiduciary is not new. But it’s even more vital in a world of generative AI assistants.

And we need one final thing: public AI models. These are systems built by academia, or non-profit groups, or government itself, that can be owned and run by individuals.

The term “public model” has been thrown around a lot in the AI world, so it’s worth detailing what this means. It’s not a corporate AI model that the public is free to use. It’s not a corporate AI model that the government has licensed. It’s not even an open-source model that the public is free to examine and modify.

A public model is a model built by the public for the public. It requires political accountability, not just market accountability. This means openness and transparency paired with a responsiveness to public demands. It should also be available for anyone to build on top of. This means universal access. And a foundation for a free market in AI innovations. This would be a counter-balance to corporate-owned AI.

We can never make AI into our friends. But we can make them into trustworthy services—agents and not double agents. But only if government mandates it. We can put limits on surveillance capitalism. But only if government mandates it.

Because the point of government is to create social trust. I started this talk by explaining the importance of trust in society, and how interpersonal trust doesn’t scale to larger groups. That other, impersonal kind of trust—social trust, reliability and predictability—is what governments create.

To the extent a government improves the overall trust in society, it succeeds. And to the extent a government doesn’t, it fails.

But they have to. We need government to constrain the behavior of corporations and the AIs they build, deploy, and control. Government needs to enforce both predictability and reliability.

That’s how we can create the social trust that society needs to thrive.

_This essay [previously appeared](https://www.belfercenter.org/publication/ai-and-trust) on the Harvard Kennedy School Belfer Center’s website._

EDITED TO ADD: This essay has been translated into [German](https://netzpolitik.org/2023/kuenstliche-intelligenz-warum-wir-regulierung-brauchen-um-vertrauen-zu-koennen/).

Tags: [AI](https://www.schneier.com/tag/ai/), [essays](https://www.schneier.com/tag/essays/), [Liars and Outliers](https://www.schneier.com/tag/liars-and-outliers/), [regulation](https://www.schneier.com/tag/regulation/), [trust](https://www.schneier.com/tag/trust/)

[Posted on December 4, 2023 at 7:05 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html) • [66 Comments](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html#comments)

### Comments

[Matthias U](http://matthias.urlichs.de/) • [December 4, 2023 7:44 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429473)

You only have more options when loan approval is done algorithmically **if** the algorithm says you actually get a loan.

Whenever it says you don’t, you’re now SOL. There’s no longer anybody to appeal to.

We didn’t just replace interpersonal trust with institutionalized rules — we destroyed the very idea that interpersonal trust has any meaning. A person now can be either a human being or a banker, but they can no longer be both.

Granted that AIs, badly regulated (if at all), will make this problem worse, possibly much worse, because instead of a person hiding behind institutionalized algorithms there now no longer is a person at all. But I contend that the problem itself already exists.

Likewise data fiduciaries. They certainly are a good idea, but we need them whether or not AIs can access our data.

My second point: I submit that without introspectability there cannot be a “trustworthy” AI. We know that slightly atypical input can lead to wildly nonsensical output. AIs are not stable. When we train people there’s an external source of stability, commonly called the Real World. (We know what happens when people lose contact with it. Talk to any Chemtrail believer, 9/11 truther, MMS drinker, stolen-election warrior, etc.etc.etc.) What’s the AI equivalent? We don’t know. Ontologies that reflect (a significant subset of) the real world do exist, but has anybody even contemplated of teaching an AI to _USE_ one of these, in the sense of forcing it to map its input to one and deriving its output from that state?

Simply throwing a terabyte of text (or a labelled petabyte of image data) at the machine and expecting it to come up with a sensible ontology on its own, out of thin air, does not work and cannot be expected to work.

Pyrite Beret • [December 4, 2023 8:41 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429475)

> We … are competing for star rankings.

Star rankings ? We ain’t got no Star rankings. We don’t need no Star rankings.

Clive Robinson • [December 4, 2023 8:59 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429476)

@ Bruce, ALL,

Re : Perceived probability is not trust.

> “Trust is essential to society. Humans as a species are trusting. We are all sitting here, mostly strangers, confident that nobody will attack us.”

The paragraph you give above that statment is not realy about trust but probability.

If we even think about it and very few ever do, we know the probability of those events are very low. Less than one in a eleven thousand a year or one in four million a day for being involved in a fatal accident involving a car in the US considerably better odds elsewhere (due to regulation). And that’s the most likely of the risks unless you count yourself not putting your phone on charge.

We mainly don’t trust but walk uncomprehendingly through life, that technology has for all it’s many sins made so safe trust is not something that happens.

If we ask a fundemental question about what trust is, it’s about “making an active choice” mostly we just don’t make a choice we just do what we want/need to do as there is no perceived risk. If we did then we would most likely fall foul of “Paralysis by Analysis” and basically lock up[1].

When we do actually trust usually it’s a safe trust, that is those we know generally are not out to do us harm physically or mentally, because they do not want the result of “Do unto others, as you would have them do unto you” happening.

Howrver what we do know is that between 10-20% of the population are without empathy and driven by personal desires. For them breaching trust is not difficult as they don’t consider it in remotely in those terms. However all but a fraction of those know that breaching trust has to be done in a not obvious way lest the authorities backed by legislation and regulation to curb their desires come after them.

Basically for the most part we have no reason to trust to any great degree in our daily lives as the probability of harm is very small to the point it’s beyond vanishing so often, it’s a real shock when it does happen.

Then the MSM all to frequently blow the probability of that harm way beyond what it actually is, and that is when the problems realy arise, as probability gets tossed aside and the raw emotion of hurt comes through amplified so much by the reality of the very unlikely nature of such events.

A kidnaped and murdered child is a very very rare event when it happens it’s international news these days. But what about the vastly greater number of children killed in and by cars?

How does the perceived risks effect parental judgment over actual risk?

Arguably as the parent feels they have no choice, trust does not occur.

[1] Look at the recored behaviours when the Washington Sniper was active, or the Boston bombers.

jones • [December 4, 2023 10:55 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429479)

I think an additional consideration here is that deception is an explicit design goal of a lot of AI systems.

The purpose of a large language model is to convince a human reader that the output came from another human.

The generative adversarial network architecture is trained in a zero-sum game of deception.

Winter • [December 4, 2023 11:46 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429480)

Re: Trust is essential to society.

This cannot be overstated: No Trust, No Society

Francis Fukuyama investigated the role of Trust in Prosperity in _Trust: The Social Virtue and the Creation of Prosperity_.[1]

This relation between Trust and Prosperity has been extensively studied, for instance:

_Social capitals, social class, and prosperity in high-trust and low-trust societies_

 ‘https://www.tandfonline.com/doi/abs/10.1080/00207659.2019.1684081

 (pdf)

 ‘https://www.academia.edu/download/65472103/IJS_2020_Social_capitals_social_class_and_prosperity_in_high_trust_and_low_trust_societies_Fuzer_et_al.pdf

> Inequalities in social capital are accepted today as important aspects of social and economic prosperity. This analysis utilizes global comparative data from the International Social Survey Program and finds substantial variation in the three types of social capital across social classes, in a cross-country perspective as well as among two types of societies, 10 high-trust and 13 low-trust societies. Social capitals show significant correlation with economic and social prosperity outcomes as well. The authors find that in more prosperous countries there is an abundance of bridging and linking social capital, whereas people in economically and socially less prosperous societies rely more on bonding social capital. The authors also present evidence on the class-related inequalities of social capitals: More advantageous class positions are associated with higher levels of bridging and linking social capital, whereas the lower classes hold higher levels of bonding social capital. Based on a multilevel analysis that brings together all of these aspects as well as a number of individual-level predictors, they conclude that their initial findings are reinforced with only minor exceptions.

[1] See review in: ‘https://www.goodreads.com/book/show/57980.Trust

[orcmid](https://orcmid.github.io/) • [December 4, 2023 12:24 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429482)

I was distressed yesterday when Bing Chat spoke to me in the first person. That’s a terrible thing to do.

On reflecting about that now, I realize that Amazon Echo gets away with it ever so easily. The Alexa voice speaks in the first person when offering to put something on my wishlist and I didn’t catch it. And I tend to respond to that voice in a personal manner, as when I say “No, thank you.”

That would be a simple thing to regulate. It should be.

Winter • [December 4, 2023 12:51 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429484)

> I was distressed yesterday when Bing Chat spoke to me in the first person. That’s a terrible thing to do.
> 
> 
> On reflecting about that now, I realize that Amazon Echo gets away with it ever so easily. The Alexa voice speaks in the first person when offering to put something on my wishlist and I didn’t catch it.

[https://www.gocomics.com/nonsequitur/2023/12/03](https://www.gocomics.com/nonsequitur/2023/12/03)

JonKnowsNothing • [December 4, 2023 1:30 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429485)

@All

re: _Who do you trust?_ (1)

A great many stories, movies, novels all center around trust. Who can you trust to keep your secret, watch your back, protect and hide you from others trying to find you (2).

At some point, the most trusted person in the story is found to be untrustworthy. They are double, triple, quadruple moles. (3)

The ending part oozes revenge with a big helping of schadenfreude.

The US Marine Corps, boot camp training, goes to great lengths to teach recruits that

1) They are not “I”, they are “this recruit”

2) The only ones they can trust are fellow Marines. No One Else.

Former Marines carry this indoctrination through their whole life. All you have to do is say Sempre Fi.

So, if art imitates life, can we expect big helpings of revenge and sides of schadenfreude – well done?

Do you think AI is susceptible to “Room 101, which contains each prisoner’s worst fear”?

When the power grid fails globally I suppose we will find out what AI’s worst fears are.

===

1)

 ht tps://en.wikipedi a. org/wiki/Who_Do_You_Trust%3F

*   Who Do You Trust? 1956 (originally titled Do You Trust Your Wife? until July 1958) is an American television game show.
*   In the quiz portion, Carson would tell the male contestant the category of the upcoming question; the man would then have to decide whether to answer the question himself or “trust” the woman to do so.

Fun US TV Factoids

*   … Johnny Carson was installed as host. This version aired from September 30, 1957 to November 15, 1957, at 4:30 pm Eastern on ABC, and from November 18, 1957 to December 27, 1963 at 3:30 pm Eastern. 
*   The initial Carson-era shows were announced by Bill Nimmo. A year into the run, Nimmo was replaced by Ed McMahon, and from that point until 1992 Carson and McMahon would spend the majority of their careers together.

*   Carson and McMahon departed after the show of 7 September 1962, when Carson was hired to take over from Jack Paar on NBC’s Tonight. Carson and McMahon would spend the next thirty years together as host and sidekick on that show.

2)

 ht tps://en. w ikipedia.or g/wiki/Righteous_Among_the_Nations

3)

 ht tps://en.wikipedia.or g/wiki/Len_Deighton

ht tps://en.wikipedi a.org/wiki/Berlin_Game

h ttps://en.wikipe dia.o rg/wiki/Mexico_Set

ht tps://en.wikipedia . org/wiki/London_Match

ht tps://en.wikipedia. org/wiki/Bernard_Samson

yet another bruce • [December 4, 2023 1:43 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429486)

@Bruce

Wow, thank you! The insights were new to me and very compelling. The piece is also very well written. I love the idea of a data fiduciary.

Jeff M • [December 4, 2023 2:02 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429487)

Here’s something Bruce didn’t address. Corporations might not be able trust their own AI:

. The Robots Will Insider Trade

 . [https://slashdot.org/story/23/12/04/1525256/the-robots-will-insider-trade](https://slashdot.org/story/23/12/04/1525256/the-robots-will-insider-trade)

A • [December 4, 2023 2:20 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429488)

I broadly agree with the essay’s thesis.

As an aside, I found myself tripping over the “social trust” definition, perhaps due to interference from the “social norms vs. market norms” distinction in behavioral economics, where social norms are more aligned with what the essay called “interpersonal trust” here.

Perhaps “service trust,” “market trust,” “contract trust,” etc. would be a clearer label for the concept.

Craig Finseth • [December 4, 2023 2:41 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429489)

“Trust” is one of those words that has an implicit assumption. Sort of like “drink,” where the assumption is that to have a drink is to have an alcoholic drink.

I trust lots of organizations. However, many of them are trusted to act against my best interest.

So, when one says trust, one should also add what you trust them to do: I trust that a mugger will attempt to get my money.

Ollie Jones • [December 4, 2023 3:07 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429491)

Another vital thing government scrutiny makew it possible to trust:

Putting our children on a school bus and sending them to school every day.

JonKnowsNothing • [December 4, 2023 3:31 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429493)

All

re: _Food safety Food chain trust_

One thing that will rile up the government, farmers, growers and distributors is if there is any hint at all questioning US food safety.

This is a mandatory trust.

The Congress and Senate Ag Committees are some of the most powerful committees and control vast sums of funding (that’s actual money in the till).

Even the CDC has to tread carefully over any recalls and how they can be minimized. Not too prominent reporting, not too much in MSM, a 8×10 sign on the market door, which hangs next to all the other current warning signs.

If one makes noise about food safety expect a severe backlash.

===

ht tps://en.wikipedia. org/wiki/Food_libel_laws#Texas_Beef_Group_v._Winfrey

vas pup • [December 4, 2023 7:26 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429495)

@Bruce – thank you – many good and fruitful ideas but rather idealistic than practically being implemnted.

My points:

 1. Trust should be mutual. If government through ubiquitous surveillance and snitching programs consider almost all citizens as potential criminals, fraudster, foreign agents – you name it then your trust back level to it as a whole very small.

 2. Same as in 1. applied to any interpersonal relationships ‘and relationships to corporations. E.g. small print, pro-forma contracts when person have zero power for negotiation – sign it or gfy. – banking account, privacy policy, data sharing – all corporations looks like scam bags with tools developed by their law departments for taking advantage on consumers – no going to court – arbitration only cause – is clear example. AI will be trains by those scam-bags as well – no way around.

 3. Government as we have with lobbyist in legislative branch and revolving doors for top officials in executive branch and corporate boards, universities is not serving average Joe and Jane at all but their own interest regardless where those person serve. Same will be with AI regulation.

 4. Bureaucracy with deep state mentality: presidents and governors come and go and we stay as basis for stability and if needed suppress any decent.

 5.Regarding “We already have a system for this: fiduciaries. There are areas in society where trustworthiness is of paramount importance, even more than usual. Doctors, lawyers, accountants…these are all trusted agents. They need extraordinary access to our information and ourselves to do their jobs, and so they have additional legal responsibilities to act in our best interests. They have fiduciary responsibility to their clients.

We need the same sort of thing for our data. The idea of a data fiduciary is not new. But it’s even more vital in a world of generative AI assistants.”

After law offices of lawyers are raided and ALL relevant or irrelevant information is taken by LEA/collected, when lawyers forced to testify in a court on their clients, when client-lawyer, doctor-patient privilege communication can be subpoenaed – what kind of fiduciary you are talking about? We have to take 5th now with any conversation with any person. Same would be with AI.

1.   Trust should be preceded by respect. There are professional activities where lie should be presumed: e.g. LEA ask you question not to get information but to entrap you using paragraph 1001, Title 18 already know the answer to the question they do answer. Psychologist have hidden agenda of any test conducted rather than openly stated to the subject. You may extend the list by yourself.

StephenM • [December 4, 2023 9:54 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429496)

@Bruce

> And that means regulation. Not regulating AI, but regulating the organizations that control and use AI.

Is there really a distinction to be made here?

JonKnowsNothing • [December 4, 2023 11:49 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429499)

@Ollie Jones, All

re: _Government + Putting our children on a school bus_

It would be useful to consider WHICH part of government is in charge of school buses. Laws regarding how school buses are made, design, color, safety features come from different sources.

Generally the Local School District (USA) takes over the day to day running of the bus. Sometimes the drivers are volunteers, other times they are paid employees of the local school district.

The Feds and State portions have little to do with it, other than sending funding for the bus.

RL tl;dr

> In a large rural county in California, the distant ranches are far from the central community and the schools. A school bus used to make the RT to the rural ranches to pickup and drop off the children. A library bookmobile made the trip down to the far end of the county too.
> 
> 
> As part of an austerity drive from the county and city elected officials, it was decided that the county and city had no responsibility to pickup the children from the rural ranches and bring them to the town for school. So the school bus service stopped. Parents from those ranches had to drive RT x 2 a day to take the children to school, go back to the ranch for work, and return pick them up after school.
> 
> 
> The library bookmobile was stopped because
> 
> 
> * My cows don’t read
> 
> 
> There were attempts to shut the library too but there was too much opposition from parents who did want their children to read.

JonKnowsNothing • [December 5, 2023 12:08 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429501)

@StephenM, All

re: _@B: And that means regulation. Not regulating AI, but regulating the organizations that control and use AI._

_@S: Is there really a distinction to be made here?_

USA laws have lots of loopholes and the biggest one in Social Media and Big Tech is the one that indemnifies corporations for user supplied content. They can take down offensive postings but the corporations hold no responsibility for those posts.

So, regulating corporations over AI content, query, and response is going to fall into the same pit. It provides enough shelter to avoid any but the biggest lawsuits and the settlement agreements will be the amounts of seconds-of-profit.

A MSM reported case in AU, the content of personal information on a work provide computer was deemed to be part of work, and the employer had rights to search and review all that data. (1) While the emails where the property of the employee, their presence on a work computer made it property of the company, enough so the company could look at it all.

*   Relevant means All, because you won’t know what’s relevant until you looked at everything.

===

HAIL warning

1)

 ht tps://www.theguardi an. com/australia-news/2023/nov/30/australian-privacy-watchdog-refuses-to-investigate-employer-that-allegedly-accessed-employees-personal-emails

*   Australian privacy watchdog refuses to investigate employer that allegedly accessed worker’s personal emails
*   [employee] had used his work laptop for personal activity, including saving his passwords for online banking, emailing from his personal account and accessing his online cloud storage
*   the work computer was not your private property, and that any data saved to the computer may have formed part of your employee records, as it was subject to routine monitoring
*   The [employer] does not require your consent to access or use the equipment that it issued to you to perform your employment duties. As the computer was a tool the respondent provided to you to carry out your employment duties, it remains the property of the [the employer].

1&1~=Umm • [December 5, 2023 2:13 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429505)

@ StephenM,

> “Is there really a distinction to be made here?”

Yes.

You need to think of the AI as what it is, “a tool” that acts as a “force multiplier”, just like a hammer, screwdriver, or powered tool.

If you get hit you over the head with a hammer,

1, Is the hammer guilty?

 2, Is the hand that held it guilty?

 3, The arm that swings it?

 4, The mind that commanded the actions?

You will find on this blog people talk about the principle of “The directing mind” as does legislation.

Where it gets stupidly snarled up is the idiocy of “legal persons” not “natural persons”,

A natural person such as you or I have a finite life span in which to live, thrive, profit and live out our finite span in freedom. That is why imprisonment is a punishment, our freedom, ability to earn for later life, to be a part of society and live as we chose is curtailed.

A legal person such as a corporation was once a piece of paper, now a string of bits. It has a life span that is indeterminate and dependent on choices made by natural persons who direct in it’s name. It does not live, it does not thrive, it does not profit and it has no freedom. It can not be imprisoned, and fines do not hurt it (just those employed by it and tax payers who might have benifited from tax payed).

All a corporation is, is a legal “fire break” for those that direct it, a way to avoid the consequences of their actions.

In effect a corporation is a way of shifting responsability for a natural person’s directed actions into a hole in the ground that they can simply walk around. Then walk away often to just carry on the same day.

As a natural person to be held legaly responsible as an officer / director of a company or corporation means three things,

1, Your actions were especially egregious.

 2, You did not document others as responsible.

 3, You were incompetent in carrying out your actions.

Thus any responsibility that might fall on the “Directing Mind” of a “Natural Person” can be avoided even murder can become “corporate manslaughter” with a “here’s 50k for the bereaved” and so sorry “we will change our processes” and “here’s a million fine to a government agency” on a “no fault basis” to show we understand that “our systems were insufficient”…

Have a look at some of what is going on behind Australia’s Snowy 2.0 hydro project,

‘https://www.news.com.au/finance/work/at-work/supermax-prisoners-are-served-better-food-union-erupts-over-workers-abysmal-conditions-at-snowy-20-site/news-story/b8ccf3d69b6443b026c2bbfcc7962d53

Fred • [December 5, 2023 6:57 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429519)

Such a fine read. Thanks.

Re: AI and art. Others have noticed this connection.

> We can never make AI into our friends.

I enlist Stanley K. and Brian Aldiss to soften the “never”

I’d also like to add a reference which relevance isn’t obvious from its URL. The title of the essay is “High-Pressure Steam Engines and Computer Software”

[http://www.safeware-eng.com/system%20and%20software%20safety%20publications/High%20Pressure%20Steam%20Engines.htm](http://www.safeware-eng.com/system%20and%20software%20safety%20publications/High%20Pressure%20Steam%20Engines.htm)

[Bion Howard](http://atomiclogic.com/) • [December 5, 2023 7:09 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429521)

Just feel compelled to chime in here and point out almost every AI company has a clause in their terms of use which I call a “customer noncompete” which implies customers are forbidden from using the AI output to compete with the AI company. Spotted on Microsoft, OpenAI, Amazon, Anthropic, and NVIDIA. The scary thing is, these AIs literally “take you” .. when you use them, you give them training data for them to learn how to imitate your mind. That’s the whole basis of the technology: imitation games.

Bruce, here’s a “prompt”: can you please do a deep dive on this concept of “customer noncompete” … does this kind of clause violate the Sherman Antitrust Act?

How is it OK for AI companies to argue “fair use” to imitate copyrighted content, while also forbidding paying customer “fair use” of AI output which humans both paid for and piloted the AI to generate?

Also, what are the security implications of AI companies being able to imitate us? Is this a case of “the more you use it, the more they ‘take’ you?” That’s terrifying.

Clive Robinson • [December 5, 2023 8:09 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429522)

@ Bion Howard, ALL,

Re : Be afraid, be very…

> “Is this a case of “the more you use it, the more they ‘take’ you?” That’s terrifying.”

Look at ot logically,

1, LLM’s posses no inteligence.

 2, They don’t actually learn.

 3, They are designed to fool.

 4, They steal what they can.

 5, They build databases with what they have stolen.

Basically it’s a match for a “persuasive surveillance tool”…

Those databases are basically PPI and very valuable to data brokers and the like.

In turn the data broker products are very valuable to certain authoritarian agencies.

Who unlawfully and without oversight use those products to arrest and incarcerate people or bring them into disrepute and bankruptcy.

Can you win at their game “NO”.

At the end of a well known –but not so much watched these days– fourty year old movie a War Games computer after loosing repeatedly at tic-tac-toe goes on to repeatedly loose at global thermonuclear war. Then after a momets pause observes,

“Strange game. The only way to win is not to play.”

To quote a real human,

“The more things change, the more they stay the same”

bl5q sw5N • [December 5, 2023 9:36 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429525)

Trust is a secondary, a consequence of other more primary characteristics. Also trust is being valued here for its importance in aiding prosperity, which is again a secondary aspect of human existence.

The primary reality involved is justice, which is “the good of the other”. Humankind is morally obligated to justice by its nature as intellectual beings knowing truth.

In our imperfect world, straying from justice is prevalent. It is the primary purpose of government to ensure justice. All functions of government derive from this. “Regulation” has to be sen as and is limited to ensuring activities of business conform to justice.

Anonymous • [December 5, 2023 10:27 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429528)

> They try to regulate the AIs and not the humans behind them.

Yes that seems like a mistake because we don’t know how to punish an AI.

minimax • [December 5, 2023 11:24 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429536)

This “threat” sounds like salespeople. What do you think a financial advisor does? They are friendly and eager to help, they have access to all your financial info. Relational and intimate. But they still try to sell me junk products! My travel agent is nice, but their hotel choices happen to give them large kickbacks. I went to a dentist (only once!) who was pressuring me to get braces. And we are all familiar with car salesmen, aren’t we?

This is the least threatening threat. The problem with predictions is the further in the future you go the more speculative it gets. Pretty soon you’re just remixing your favorite sci-fi movies.

There are real short/medium term issues to consider. The general black-box nature of NNs. Bias in training data. Some groups of workers could lose their jobs. Massive disinformation campaigns. Automated killer drones.

PaulBart • [December 5, 2023 12:06 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429540)

@ Matthias U

“We know what happens when people lose contact with it. Talk to any Chemtrail believer, 9/11 truther, MMS drinker, stolen-election warrior, etc.etc.etc.”

Yes. History has shown the benevolence of democratically elected governments and their appointed state bureaucrats. Talk to any Russian hoax believer, nanny-state do-gooder, where is my ‘free’ stuff champion, Assange who? forgetter.

Gert-Jan • [December 5, 2023 12:39 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429542)

Trust is not all or nothing about everything.

When I buy a light bulb, I trust the seller and manifacturer to give me one that works. I trust the seller to take care of it, if it turns out it’s broken when I’m arrive home and find that the light bulb is malfunctioning. I don’t trust the seller to still be in business 6 months later. I don’t trust the manifacturer to have provided a light bulb that works longer than the specified amount of light hours or on/off switches. I don’t trust the manifacturer to be socially responsible. I don’t trust the seller to be socially responsible.

In general, I trust that open source software is built with the intention to be safe, to function as specified, to fail in predictable, secure and safe way.

When I use commercial software, I trust the software to do the same as mentioned above. I generally don’t trust the vendor to handle my personal data securely, especially when it’s a US vendor. In general, I don’t trust the vendor to keep my data private. I trust the vendor to lie when they send me promotions and/or newsletters.

Now let’s get to AI. If you want AI that doesn’t lie, then you can’t use AI. At least not today. If you want AI that doesn’t infringe on copyrights then generally you can’t use AI. If you want AI that doesn’t spy on you (spy in the sense that it hands the data to 2nd or 3rd parties), then you’d have to be very tech savvy to get that done on a local computer, if possible at all. And I wouldn’t trust myself to be able to keep that AI collected data private under all circumstances.

Technically it could be possible to produce thrustworthy AI. It requires trust in the process that creates and maintains this AI and in the people doing it. It will be even harder (if not impossible) to trust that AI will handle the data in such a way that it is in my best interest. And that mostly hinges on security and privacy (including data retention) over time.

I trust all corporate AI to use the data to their advantage in any way they technically can. And hand it off to anyone if it serves their purpose. I trust that most actors who offer AI services (for free) will try to hide the objectives of the AI and how they use your input.

Of course you can make legislation that requires transparancy. One transparency rule that might be useful – which I have argued before – is to require any non-human to actively report itself as non-human before any other communication. Any other transparency is nice for people or NGOs who want to rate a company or solution, but if there’s no competition, if all providers “steal” your data, if all providers mislead you in every possible way, then what’s the value of transparency? The investigation about data security and privacy of electric cars is a good example.

So legislation has to focus on beneficiaries of AI, and what they are allowed (or not allowed) to use and offer AI for. And o boy, is that process going to be messy, before we get it right…

Winter • [December 5, 2023 2:39 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429547)

@Gert-Jan

> Trust is not all or nothing about everything.

The examples you give are more about probability or reliability. But these are not about social Trust.

Social Trust is about the believe someone will do what is good for you, that they will warn and help you if needed. That they will not lie to you when it matters, and not snitch about you when it would damage you.

Homo Sapiens Sapiens Bullshit - The inventor of stories • [December 5, 2023 5:48 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429551)

@Bruce

> I wrote about this in 2012 in a book called Liars and Outliers. I wrote about four systems for enabling trust: our innate morals, concern about our reputations, the laws we live under, and security technologies that constrain our behavior. I wrote about how the first two are more informal than the last two.

Interestingly

“our innate morals” have been in a state of flux due to religion losing most of its authority.

“concern about our reputations” likewise has changed. Earlier generations might say that many in modern society have no shame. One example of this is the epidemic of shoplifting across USA.

Granted there is still the “reputation” controlled by the ratings in a smartphone app like that by Uber. And that works only in the current context, where people see a need to utilize services like that. That need leads to a sufficient amount of users willing to reach for a high enough rating.

justina colmena • [December 5, 2023 11:02 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429556)

“Project Paperclip” being what it was, a heavy infiltration of Nazis in the U.S. government after WWII, a recent post by FBI highlights fears of “warrant-proof” encryption schemes presumably without back doors or “LEAF” type law enforcement access fields.

[https://x.com/FBI/status/1732173127667360106](https://x.com/FBI/status/1732173127667360106)

Winter • [December 6, 2023 1:09 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429559)

@Homo

> “our innate morals” have been in a state of flux due to religion losing most of its authority.

The followers of which religion are the moral ones? Or, if it is all of them, which are the _correct_ morals?

Winter • [December 6, 2023 1:16 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429560)

@PaulBart

> Talk to any _Russian_ hoax believer, nanny-state do-gooder, where is my ‘free’ stuff champion, Assange who? forgetter.

_emphasis mine_

I would say, talk to any contemporary citizen of _Russia_ about trust. That should be illuminating.

They have the advantage of living in a state that never [1] had a democratically elected government.

[1] The situation in the 1990’s in Russia can be debated. It lasted too short to draw any conclusions.

bl5q sw5N • [December 6, 2023 8:07 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429569)

@ Winter @ Homo Sapiens …

> The followers of which religion are the moral ones?

Human morality follows from human nature, especially rationality, So in principle morality is knowable by reason. Obviously with great difficulty.

Rationality lays an obligation to truth in every question, including the questions about god, such as existence and relationship to humankind. The best treatment of these as philosophical inquiries starting from the physical world is probably Aquinas’s Summa Contra Gentiles. (Aquinas in this work takes on all comers from all points of view natural and also religious.)

In dealing on the natural rational plane with these questions about morality (which includes questions about god), it becomes apparent that there is no good in the natural world that satisfies humankind fully, and also that even knowing moral truth, humankind chooses often to disregard and attack it. This paradox of futility raises the question of how this can be. There is no rational answer in natural terms. To answer this question a turn to religion is necessary. But what religion has an answer that does not offend reason ?

Chesterton points out that for the pagan world, e.g. the Icelanders at the Althing, this was often Christianity.

Clive Robinson • [December 6, 2023 8:45 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429570)

@ Winter, Homo Sapiens, ALL,

> “The followers of which religion are the moral ones? Or, if it is all of them, which are the correct morals?”

The correct answers,

1, Deity worship is a long con game, thus is fundementaly very amoral and would be criminal activity if judged honestly and with impartiality.

2, Morals are fundementaly sociality driven, by the simple “Do unto others as you would have done unto you” ethic, which is how we have the agreed upon “rights”.

Hence my repeated point of,

“Indicidual Rights v. Social Responsibilities”

The problem however goes back to the “King Game” where a thug or worse makes themselves “the god head” to arms length both social responsability and moral controls, but gain significant control over society through fear etc.

In effect the “church” ever looking for power and control it’s self becomes the equivalent of the thugs “guard labour” and “political control” unit, and yes in times past the “secret police” and similar terrorising communities in a “Might is Right” argument for claiming to “hold the moral high ground”.

The reason it works is the focus on young children, to in effect “brain wash” them before their brain has built defenses against such nonsense. It’s why women are treated the way they are by many deity worship religions / cults, because they are the conduit to the children.

When you think about it dispassionately it represents the worst form of “grooming” you can imagine and why so many established churches are getting the evil they harbour and turn a blind eye to outed.

Winter • [December 6, 2023 9:08 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429572)

@bl5q sw5N

> To answer this question a turn to religion is necessary. But what religion has an answer that does not offend reason ?

Which religion? They each claim to be the sole origin of moral righteousness with the exclusion of all others.

All religions claim to be the one and only origin and protector of the correct morals. But they all claim different morals as being the one and only God given morals.

All humans have morals, irrespective of their religion or absence thereof [1]. So the “natural” conclusion is that morality is innate in humans, and all religions parasitize on that morality to further their own aims.

In reality, morals are just one of the innate behaviors that allow humans to live in social groups. Religion comes _after_ the emergence of morals.

[1] The ‘Ndrangheta and Hamas have strong morals and are very religious. In both cases religion is just an excuse to prey on other people and feel good about it.

 ‘https://www.occrp.org/en/ndrangheta/italys-most-powerful-mafia-mingles-with-devoted-christians-at-the-sanctuary-of-polsi-in-calabria

bl5q sw5N • [December 6, 2023 12:00 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429577)

@ Clive Robinson @ Winter

Re: con artists, which religion

The fact that con artists use religion as a basis for their fraud or that bad men are religious says nothing against gods or worship thereof as such. Anything and everything has been used. Are property and medicine intrinsically non-existent, fraudulent, or evil ? They are among the most widespread bases for swindles, and bad people make regular use of them, owning property and going to doctors.

Likewise, every variety of religious belief, systems of morality/ethics, and societal practice can be found. Just because a social group has certain mores does not mean those mores correspond justly to human nature or to a human good. The cannibal is sincere in his cannibalism. That is basically the same type of error as the “con” argument, namely.because some people good or bad do something that thing is likewise good or bad.

The specific religious doctrine has to be considered intrinsically in the light of reason. As mentioned above, Aquinas’s Summa Contra Gentiles is a good resource for this exercise.

Winter • [December 6, 2023 12:38 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429578)

@bl5q sw5N

> The fact that con artists use religion as a basis for their fraud or that bad men are religious says nothing against gods or worship thereof as such.

It does tell us that religious people are not “better” morally than atheists[1]. In short, it tells us religion does not give us better morals.

That was implicit in the original claim above:

 @Homo

> “our innate morals” have been in a state of flux due to religion losing most of its authority.

[1] There is no empirical evidence that atheists are less “moral” than religious people. They just do not follow church rules, like not eating meat on Friday, or not attending mass, or cohabitating without church mariage.

fib • [December 6, 2023 2:38 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429581)

@ Winter

> There is no empirical evidence that atheists are less “moral” than religious people.

I dare say that in an increasingly secular, homogeneous world, moral systems will increasingly tend towards the Categorical Imperative* and similar principles in other moral-philosophic traditions. It is the natural moral system of the ‘enlightened’ man.

*https://en.wikipedia.org/wiki/Categorical_imperative

bl5q sw5N • [December 6, 2023 3:04 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429584)

@ Winter

> It does tell us that religious people are not “better” morally than atheists[1]. In short, it tells us religion does not give us better morals.

The character of people who in some fraudulent way associate themselves with religion does not say much about people who genuinely are religious. “Be doers of the word and not hearers only.”

As Chesterton says, “Christianity has not been tried and found wanting; it has been found difficult and not tried.”

John • [December 6, 2023 3:29 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429585)

“But only if government mandates it.”

Government is a corporation that has power to create/destroy other corporations and use force against humans appearing to violate government/corporate rules. Any lack of trust one should have in a capitalist corporation one should have in any government. Legislative == Board of Directors, Executive == CEO + management, Judicial == General Counsel with employment guarantee. Government is no better than the humans in power, and often worse due to the immense size and competing cliques which develop and persist.

Governments do not automatically serve a society; governments serve those with power, just like corporations. If the powerful want a fair and trustworthy society, they will require a fair and trustworthy government. AI will amplify the benefits as well as faults of government.

“Because the point of government is to create social trust.”

People create social trust. Government is a mechanism for enforcing consequences to violations of social trust. A large number of governments are currently failing to create or even maintain social trust in spectacular fashion.

Quis custodiet ipsos custodes?

Cyber Hodza • [December 7, 2023 3:33 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429598)

@Bruce – Let’s face it- governments can’t be persuaded to do things which oppose interests of corporations as the latter exercise too much control over the former

Clive Robinson • [December 7, 2023 6:05 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429602)

@ Cyber Hodza, Bruce, ALL,

> “Bruce – Let’s face it- governments can’t be persuaded to do things which oppose interests of corporations as the latter exercise too much control over the former”

Have a read of,

[https://www.theregister.com/2023/11/29/uk_sim_farm_ban/](https://www.theregister.com/2023/11/29/uk_sim_farm_ban/)

The whole thing is predicated on and driven by the lost profits to mobile phone companies, that had ways to extract vast ammounts from people via a monopolistic position.

The moment a technical solution was found to reduce customer expense, in charged the authorities “whipped in” by the mobile phone company that was practicing tax evasion of an extrodinary amount, that would have put you or I in jail for “Eternity plus life”.

Cyber Hodza • [December 7, 2023 5:32 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429624)

@Clive – the real question is – is there another way of forming government which would be more resilient to interest of small but powerful few- and I actually don’t see one?

ResearcherZero • [December 8, 2023 12:30 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429640)

@Cyber Hodza

If people stop succumbing to bribery, greed and unreasonable self-interest, maybe. Every election is won using either fear, or offers of more money in the wallet. It does not take much to divide people.

If communities can resist the individual risk of outside financial influence and other forms of coercion that subvert the whole.

Sadly this requires people to work together constructively and support one another, something which human beings have a very long history of failing at. There are examples of specific communities which have a history of community support, where they do band together to support individuals. Though not completely immune from compromise, they have managed to overcome total compromise.

People love to grovel at the feet of men in suits, even cheap ones. They can’t help but fall for simple and repetitive messaging. And sell each other out for self gain. Little whispers in the ear about the wealth of others, along with lies about others making deals.

The pigs use the same tactic because it works. People have very little genuine loyalty to one another, and they rarely come to the aid of others if it might put themselves at a disadvantage. This is how they are conquered every single time.

The Evangelical Christians sell out: “Lying and manipulating and conspiring to gain political goals is, let’s be honest, pretty much a bipartisan enterprise in politics, and especially in the Oval Office. This does not justify any moral wrong, but there is a huge difference between moral wrong and criminal wrongdoing.”

[https://www.christianitytoday.com/news/2023/august/trump-indictments-evangelical-support-2024-georgia.html](https://www.christianitytoday.com/news/2023/august/trump-indictments-evangelical-support-2024-georgia.html)

Even the Commies sell out: “We are working with the Defense Ministry, the Main Intelligence Directorate. They pay us the money.”

‘https://www.rferl.org/a/redut-fake-russia-gru-pmc-ukraine/32708853.html

–

Neural networks memorise personal information from one sample. (not easy to fix)

‘https://www.nature.com/articles/s41598-023-48034-3

This attack is severe since the poison instance can be placed online and awaits to be scraped by a bot for data collection.

“Although poison samples seem normal to a user, they indeed comprise illegitimate characteristics to trigger a targeted misclassification during the inference process. […] For instance, an attacker can insert a seemingly legitimate image, i.e., a correctly labeled image, into a training dataset for a facial identification engine and thus control the chosen person’s identity during the test time.”

‘https://arxiv.org/ftp/arxiv/papers/2112/2112.02797.pdf

Remmelt Ellen • [December 8, 2023 8:29 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429645)

Lifting out this quote:

❝ A government is systemic and bureaucratic on the inside. You’re not going to mistake it for a person when you interact with it. But this is the category error we make with corporations. We sometimes mistake the organization for its spokesperson. AI has a fully relational interface—it talks like a person—but it has an equally fully systemic implementation. Like a corporation, but much more so.

AI and corporations hold something in common. They are both **artificial bodies**.

More on that here: [https://workflowy.com/s/artificial-bodies/znDloerXJaEQvKF6](https://workflowy.com/s/artificial-bodies/znDloerXJaEQvKF6)

Dan • [December 8, 2023 11:29 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429649)

Overall great points to ponder.

What happens if you can’t trust the government? The history of governments is that they eventually become oppressive. All of them. We are seeing that today. Government often takes the side of the criminal and prosecutes the victim or the person who tries to assist the victim.

Societal trust is also based on cultures. Different cultures have different expectations for behavior and definitions for what is right and wrong. The same government that we should expect to build trust in society is today doing the exact opposite through immigration and refusing to require assimilation. There have been no successful multi-cultural societies. There are lots of examples of failures.

None of this will end well.

Winter • [December 8, 2023 12:56 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429650)

@Dan

> The history of governments is that they eventually become oppressive. All of them. We are seeing that today.

The USA government has existed for over two centuries.

It started extremely oppressive with up to a fifth of the population made up of slaves with no rights, not even a right to life. The native population was not much better off. Only in the 20th century native Americans got citizenship and only in the 1960s did black Americans got effective civil rights.

So, in the USA the situation got _less_ oppressive over the last two centuries.

Many other countries showed the same pattern, with freedom increasing and oppression decreasing over the last two centuries.

Winter • [December 8, 2023 1:02 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429652)

@Dan

> There have been no successful multi-cultural societies.

The Roman Empire “worked” for a few centuries. The USA is built upon people from all of the inhabited continents. 15% of Americans speak Spanish at home.

Still works.

Winter • [December 8, 2023 1:07 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429653)

@Dan

> There have been no successful multi-cultural societies.

PS:

 The Turkish empire did pretty well between 1450 and 1850. So did the Habsburgian Austrian Hungarian double monarchy for a few centuries.

I would say: Busted.

Dan • [December 8, 2023 2:56 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429659)

@Winter

Speaking a different language is not the same thing as having a different culture. It is part of it, but not all. Early immigrants to America all spoke different languages, but they also made it a priority to assimilate into the American culture. That view is seen as racist or oppressive today.

All the empires that you cite used force and coercion to keep the peace between the different cultures and conquered territories. People didn’t voluntarily join the empire. They were conquered.

You could have also included Yugoslavia, which is a more recent example. Tito kept the peace between the Serbs, Croats and Muslims by dealing forcefully with the troublemakers. When he was gone, the cultures started clashing again. I witnessed it first-hand.

I’ve lived in three different countries and always tried to assimilate to the culture of the country that I was living in. I feel it is reasonable, and it’s the only way to keep the peace.

But – this blog is about trust, and more specifically on the topic of trust in government to ensure that AI is used fairly and reasonably. My point is that when a large percentage of the population does not trust the government, and when the government is actively engaged in eliminating long-held cultural norms, we cannot hope that the government will be trusted to ensure that the entities controlling AI are held to task.

ResearcherZero • [December 8, 2023 7:09 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429663)

@Dan

There is a little thing called law, and other thing called protocol. Both people agree upon for the sake of for fair and civil society. Either do not require conquering.

There are civil courts where people settle disputes. The same setup existed long before written or modern interpretations of law, and they worked in a very similar manner.

Governments are made up of people. They are a cross section of human behaviour. That behaviour has nothing to do with the language or culture each individual practices. It is human behaviour, often unsophisticated, petty and pathetic. Be it at home, on the street, or in the halls of government, or perhaps even the kiddie’s playground.

‘Ministerial responsibility? I’ll show you responsibility sunshine!’

Alleged rape in parliament house. Coaching the accused. How to get away with very bad behaviour in politics by interfering in, and abusing the legal process…

“Reynolds’ claims the decision to publish a letter under freedom of information laws resulted in defamation.”

‘https://www.theguardian.com/australia-news/2023/dec/07/linda-reynolds-sues-act-government-leaked-letter-shane-drumgold-afp

“Michaelia Cash claims she was not allowed to participate in process that led to personal injury settlement between federal government and Higgins”

‘https://www.theguardian.com/australia-news/2023/dec/08/michaelia-cash-claims-pm-denied-her-right-to-defend-herself-before-government-paid-245m-to-brittany-higgins-nfbntw

The behaviour of people in civil and family courts is not any different than what you see in the halls of power. Human behaviour within the courts is petty and selfish, along with the same abuse of process that occurs within government.

(It does improve somewhat if you stick a video camera in their face, and make it available for public broadcast.)

ResearcherZero • [December 8, 2023 7:17 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429664)

Another way to settle disputes, is for two people to stand opposite each other, and then take turns to hit each other over the head with a piece of wood. Often people choose mediation instead. They should introduce it as an option at the UN. Simpler than warfare.

Strictly no VETO allowed by permanent members upon commencement of said option.

ResearcherZero • [December 8, 2023 8:06 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429669)

@Dan

War is a very expensive business, with long loan repayments or punitive settlements.

Security is gained through mutual trust, often by means of dialogue. Even after warfare, opposing parties must sit down, negotiate and come to terms of agreement and treaty. It can be an ongoing process that takes a very long time for both parties to reach an acceptable conclusion. Settlements from both world wars have only recently reached conclusion.

The U.S. massively raised taxes to pay for WWII. 60% on capital and 18% on labour. Debt was above 100% of GDP. The final costs of war are vague, with true financial cost much greater than reported, or ever settled.

The postwar financial system created a “forced home bias” through capital controls, and kept high reserve requirements for banks. This built a captive domestic audience of government debt buyers.

[https://www.nber.org/system/files/working_papers/w16893/w16893.pdf](https://www.nber.org/system/files/working_papers/w16893/w16893.pdf)

“Definitive settlement is financially essential for both debtor and creditor nations. In view of the lower rates of interest likely to prevail in times of peace, we have agreed to standard rates of interest substantially lower than those in the original contracts. Further to facilitate payment by the debtors we have agreed to still lower rates in the first ten or more years, and to extend the term of payment over a long period. Finally, in cases where the payment of these rates appears beyond the capacity of debtor nations to make without endangering its budgetary equilibrium, currency stability, and standard of living, we have agreed to still lower rates during more of the period.”

[https://www.vqronline.org/essay/war-debt-settlements](https://www.vqronline.org/essay/war-debt-settlements)

“The Treaty of Versailles didn’t just blame Germany for the war—it demanded financial restitution for the whole thing, to the tune of 132 billion gold marks, or more than $500 billion today.” …**It took 92 years for Germany to pay off the debt.**

[https://www.history.com/news/germany-world-war-i-debt-treaty-versailles](https://www.history.com/news/germany-world-war-i-debt-treaty-versailles)

_“If we were going to fight WWII today, and we said hey, you know what, we’re gonna have the fed work with the Treasury to fix the return at 3/8ths of one per cent, good luck in trying to do that, are you going to find buyers for that?”_

‘https://www.ft.com/content/e4eec640-321e-3cfe-9b82-46bacfa4d6bc

ResearcherZero • [December 8, 2023 10:05 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429672)

Law and culture change over time. They are two separate things. People follow the laws of different nations, rather than entirely change religion or other defining cultural practices (such as language) each time they go on holiday or move location. Often also respecting local protocols of behaviour because it is polite, and assists negotiating a new location.

Is culture art? Is it religion? Is it language? Is it “throw a shrimp on the barbie, mate.”

“**law and culture** differ in fundamental details, including: (a) the identity of those who initiate the rules; (b) the rules’ underlying purposes and values; (c) how these rules are (i) initiated, (ii) developed, (iii) expressed, (iv) and enforced; and (d) the extent of their acceptance by those to whom they apply.”

[https://www.bu.edu/bulawreview/2021/12/30/law-and-culture/](https://www.bu.edu/bulawreview/2021/12/30/law-and-culture/)

Examining cases of legal appropriation and the kinds of cultural meanings and social transformations that result provides a more dynamic and agentive way of understanding the linkage between law and culture.

“Cultural forms and practices are locally expressed but connected to global systems of economic exchange, power relations, and systems of meaning. They are constructed and transformed **over historical time** through the activities of individuals as well as through larger social processes.”

‘https://scholarship.law.gwu.edu/cgi/viewcontent.cgi?article=1087&context=faculty_publications

In many cases, however, the legal culture allows for more than one possible solution. Therefore, while there may be objectivity in the law, there is also a degree of inconsistency in its application.

[https://scholarship.law.cornell.edu/cgi/viewcontent.cgi?article=3206&context=clr](https://scholarship.law.cornell.edu/cgi/viewcontent.cgi?article=3206&context=clr)

Culture is the way in which _“we create our experience, knit together disparate ideas and actions, and in the process fabricate a world of meaning that appears to us as real.”_

The law commonly understands itself as enforcing “the common sense of the community, as well as the sense of decency, propriety and morality which most people entertain.”

**Not surprisingly, defining “culture” is a complicated task.** Indeed, scholars have long wrestled with this definitional question, and there is no necessary agreement on what the term encompasses.

‘https://openyls.law.yale.edu/bitstream/handle/20.500.13051/7263/25_10YaleJL_Human575_1998_.pdf

JonKnowsNothing • [December 9, 2023 12:09 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429674)

@ResearcherZero, All

re: _Security is gained through mutual trust, often by means of dialogue. Even after warfare, opposing parties must sit down, negotiate and come to terms of agreement and treaty._

No.

After a war, skirmish or battle, the victor dictates the terms and reparations. The parties do not have to agree and they do not ever “come to terms” with what is required. Especially the losing party, never comes to terms.

Rhetorical Question:

*   How happy do you think any conquered civilization is to be conquered?
*   Do you think they sing hosannas to the victors because they are happy about it?
*   Do you think they do not remember the wars, deprivations, displacement?

Historically, the number one goal of any victor is to crush their opponent so far into the dirt they will never again dare to challenge The Might of Rome. This aspect leads, over and over and over to renewed conflicts and renewed resentment.

There are lots of books about the nature of war, how modern and historical governments get people to line up and slow walk out of the trenches into the machine guns. 1,000,000 a day did it. So it’s not hard to determine that what worked then will work now, because humans haven’t done much to change their mental view of “Other”.

There are lots of books about how a particular battle sequences unfolded. How the Grey ran into the Blue Gatling Guns and didn’t see them. How Alexander crossed from Greece through Afghanistan into India and routed all the armies between. How the Greeks and Persians fought battle after battle after battle, each side winning some and each side losing some, and every time it was “the last time”; only it wasn’t and isn’t.

There is economic value in wars. First the physical and logistical aspects of war. Our USA Shock and Awe took months to even get started. The logistics are money for the taking. After the logistic profits come the long term reconstruction and reallocation of property, wealth and goods.

Rhetorical Question:

*   Do you think the UKR, UK, EU and USA are just going to give back all the loot they took from the RU Oligarchs? 
*   Do you think that in the many lands where there are border disputes and cultural schisms all will just go back, as is, to the displaced?

*   Do you think that colonial empires, will return 100% of all lands, goods, material taken?

*   That your house (in USA) will now belong so someone else because you are not an indigenous person?

No they won’t. The victors keep everything and leave nothing behind.

*   iirc(badly) During one of the previous skirmishes in ME, a tract of land was annexed and taken by the victors. Later a legal ruling required this land to be returned to the vanquished. In the years since the land was taken, the new owners build luxury homes, hotels, cities, urban neighborhoods, schools and roads. What was returned was the bare dirt. All the items that had been built during the Between Time were bulldozed to the ground before the hand over.

People do not forget, not even when a government orders them to do so. The families remember and cultures remember. The stories may be fragmented, however the core memory remains.

===

ht tps://en.wikipedia.org/wiki/Trojan_war

*   In Greek mythology, the Trojan War was waged against the city of Troy by the Achaeans (Greeks) after Paris of Troy took Helen from her husband Menelaus, king of Sparta.

ht tps://en.wikipedia.org/wiki/Returns_from_Troy

*   Many Achaean heroes did not return to their homes, but died or founded colonies outside the Greek mainland. The most famous returns are those of Odysseus.

ht tps://en.wikipedia.org/wiki/Returns_from_Troy#The_Returns

> News of Troy’s fall quickly reached the Achaean kingdoms…
> 
> 
> The Gods were very angry over the destruction of their temples and other sacrilegious acts by the Achaeans and decided that most would not return.
> 
> 
> A storm fell on the returning fleet … and many were shipwrecked.
> 
> 
> [List of Major Heroes their punishment and deaths]
> 
> 
> Nestor, who had the best conduct in Troy and did not take part in the looting, was the only hero who had a good, fast and safe return. Those of his army that survived the war also reached home with him safely.
> 
> 
> Among the lesser Achaeans very few reached their homes.

Winter • [December 9, 2023 5:51 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429684)

@Dan

> My point is that when a large percentage of the population does not trust the government,

That is indeed a problem. But is it the government they do not trust? Or is it another section of society?

> and when the government is actively engaged in eliminating long-held cultural norms,

What norms? The reproductive rights of women? History of African Americans? Freedom of Religion? I know these are eliminated, but that is more local “government”.

> we cannot hope that the government will be trusted to ensure that the entities controlling AI are held to task.

But isn’t the problem that the long held norm is that the “government” should _not_ interfere?

Winter • [December 9, 2023 7:25 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429687)

@Dan

> All the empires that you cite used force and coercion to keep the peace between the different cultures and conquered territories.

But the claim was:

_There have been no successful multi-cultural societies._

These examples were very successful over centuries. They were not nice, certainly very far from it, but they were very successful.

So your claim should be read as “There have been no successful _nice_ multi-cultural societies.”

ResearcherZero • [December 10, 2023 11:02 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429727)

@JonKnowsNothing

I agree. It takes a very long time to resolve problems after conflict. The conquered party is not necessarily happy with the terms. Kinetic diplomacy, the use of force, has a checkered history full of failures. Once the killing begins, many of the “ideals” go straight out the window. No one stops to ask how well someone assimilated.

Bombs and bullets, disease, and all the other causes of death become arbitrary statistics. The ‘well-off’ may have better odds at survival, but it is no guarantee.

It’s all lip service and silver tongues. The ‘strongman’ pitch is a PR exercise, all marketing. Those people never conform to the same “values” they preach. They are the first to bolt and the last to come to the physical aid of anyone in danger.

Apparently, according to them, they are all doing it for the public. The crying and the moaning. The constant and never ending demands for attention, which eventually they get:

It could have been the Russians! They really might have tried to interfere and it might not have been a ‘hoax’, says Trump’s lawyers.

TRUMP’S MOTION TO COMPEL DISCOVERY

‘https://storage.courtlistener.com/recap/gov.uscourts.dcd.258149/gov.uscourts.dcd.258149.167.0.pdf

20/20 — “Hindsight provides a wealth of knowledge we don’t have at the time.”

25 charged with forgery, false statements and filing false documents. With more charges to come.

[https://www.businessinsider.com/trump-fake-electors-2020-gop-biden-electoral-votes-certification-2023-12](https://www.businessinsider.com/trump-fake-electors-2020-gop-biden-electoral-votes-certification-2023-12)

**There are many strange attempts by humans at conforming to a group.**

‘https://edition.cnn.com/2022/09/20/politics/surveillance-footage-coffee-county-georgia-fake-trump-elector/index.html

Other swing states, including Arizona, Georgia, Michigan, New Mexico, Nevada and Pennsylvania saw a version of the same actions take place.

[https://www.nytimes.com/2023/12/08/us/politics/chesebro-fake-electors-trump.html](https://www.nytimes.com/2023/12/08/us/politics/chesebro-fake-electors-trump.html)

_Civilly liable on plaintiffs’ defamation, intentional infliction of emotional distress, civil conspiracy, and punitive damage claims._

‘https://ecf.dcd.uscourts.gov/cgi-bin/show_public_doc?2021cv3354-119

Giuliani faces counts including conspiracy to commit forgery, conspiracy to impersonate a public officer and filing false documents.

[https://politicalwire.com/2023/12/07/georgia-prosecutors-predict-jail-sentences/](https://politicalwire.com/2023/12/07/georgia-prosecutors-predict-jail-sentences/)

JonKnowsNothing • [December 11, 2023 12:55 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429728)

@ ResearcherZero, All

re _It takes a very long time to resolve problems after conflict._

I do no think this ever happens. Even when conquered people are annihilated, their structures, cities, statues all destroyed, somehow something still remains. It seeps into those that somehow survived directly or indirectly.

*   Franco was very clever at setting up his extermination camps and mass murders throughout Spain. The camps never built durable structures. When their purpose was fulfilled, the razor wire was wound up and nothing remained in El Campo. But still the memory surfaced, hidden in the cul-de-sac of towns and villages and cities, the names of the missing and dead were engraved on the walls.
*   The Abuelas de Plaza de Mayo, do not forget. As they die, the hope of the perpetrators is that the memory will die with them. It won’t.
*   The French still cry over the defeat and death of Vercingetorix by Julius Caesar in the Roman Gallic Wars. We may think that Rome was a mighty civilization, yet it was anything but “civil”.

The hidden histories of the conquered tend to show up at awkward moments. These memories are not always the nice versions that some would prefer. You can take down the statues but you have not dealt with the issue that caused those statues to be raised in the first place. You can melt down the bronze hooves on the equestrian statues, but the iconography remains behind.

No matter what flag you wrap around your body, there are people who will remember. The victor hopes to be remembered as Great or Kind or Magnificent. The vanquished remember them for the rotting corpses and the trampled fields and the starvation and the deaths in uncountable forms.

RL tl;dr

> In a international text exchange, a person was asked about the name of their avatar: El Cid.
> 
> 
> They replied that El Cid was their greatest hero, and the greatest hero of Spain.
> 
> 
> Another person replied that El Cid, was the greatest villain in history.
> 
> 
> It was because of El Cid, that their ancestors had to leave Spain, a place they had lived for hundreds of years. They became refugees, one of several great diasporas, that happened because of his actions.

1492 marked the beginnings of more than one global catastrophe and today’s issues drag us back 600 years to when they were created.

I do not think anything ever gets resolved, it is only a temporary ripple.

ResearcherZero • [December 11, 2023 1:17 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429729)

@Dan @ALL

Stalin deported most of the Crimean Tartars, although the majority of men had fought for the Rad Army against Nazi Germany. (who are still being persecuted today under Putin)

The SS Totenkopf divided captured black soldiers from their white officers, then shot the black soldiers, who were Senegalese, and fighting for France.

France shot it’s own Senegalese soldiers, who fought against Nazi Germany, because they asked to be paid.

And Australia… remains the only First World nation, in the world, to not recognise it’s indigenous peoples formally under the law! Even our soldiers who fight for us.

“We might not be able to dig a hole deeper than two inches deep if we recognise First Nations people,” say (some) farmers. People have actually said this to me, also publicly.

Of course it is a ludicrous argument, which would not prevent the digging of holes, _even_ if we were to legal define “indigenous peoples” in law.

Native title claims can only be made on **Crown land**, though this land may be covered by a pastoral lease or other interests that are deemed by law to _prevail over native title_. Private property held under freehold, _such as your house and backyard_, has already had any native title **extinguished** under Australian law.

**And as for the digging of holes, Native Title does not extinguish a landholder’s or leaseholder’s rights.**

The native title system allows objections to mining activities and those objections are **always overruled**. This means that if Aboriginal people object to mining operations on their country, they are _precluded_ from negotiating things like royalties or compensation when the mine ultimately goes ahead.

_“under binding High Court authority, the Commonwealth’s legislative power in relation to the territories in s 122 of the Constitution is not limited by the ‘just terms’ requirement in s 51(xxxi). The second was that, because native title is always liable to be extinguished by the grant of inconsistent property rights, it is ‘inherently defeasible’ and so not a species of property that is protected by the ‘just terms’ requirement.”_

…however, _“like other forms of property, native title rights are constitutionally protected from acquisition other than on just terms.”_

(You can’t blatantly steal the little land that Aboriginal people have left, but you can get a lease from government and mine it.)

[https://newchambers.com.au/news/full-court-determines-that-native-title-rights-are-constitutionally-protected-from-acquisition-other-than-on-just-terms/](https://newchambers.com.au/news/full-court-determines-that-native-title-rights-are-constitutionally-protected-from-acquisition-other-than-on-just-terms/)

The report said not adopting a formal definition for “indigenous peoples” was deliberate.

_“This decision was taken intentionally by the drafters based on the rationale that the identification of an indigenous people is the right of the people itself — the right of self-identification and a fundamental element of the right to self-determination.”_

‘https://www.abc.net.au/news/2019-10-10/fact-check3a-is-australia-the-only-first-world-nation-with-a-c/11583706

“Indigenous people have in many instances become participants on a highly legalistic journey which, at times, twists and turns without any forewarning or regard for substantive justice.”

[https://www.jurist.org/features/2023/02/13/making-peace-with-native-title-in-australia-how-a-treaty-can-unlock-change/](https://www.jurist.org/features/2023/02/13/making-peace-with-native-title-in-australia-how-a-treaty-can-unlock-change/)

–

“lack of penalty and deterrence” — for destroying protected sights…

“Other miners may now consider doing the same thing as Sandfire… This cannot be allowed to happen in the 21st century.”

‘https://www.abc.net.au/news/2023-12-07/sandfire-resources-degrussa-mine-aboriginal-artefacts-destroyed/103196314

In this case, a journalist photographing the removal was stopped by police. Later, her home was raided and her camera’s memory card temporarily seized.

[https://www.uwa.edu.au/news/Article/2023/May/Murujugas-rock-art-is-being-destroyed-where-is-the-outrage](https://www.uwa.edu.au/news/Article/2023/May/Murujugas-rock-art-is-being-destroyed-where-is-the-outrage)

The mining industry made 144 requests to the WA Government to “impact” heritage sites between 2017-2021. _Only one was rejected._

‘https://www.parliament.wa.gov.au/Hansard/hansard.nsf/0/981c2f8d584990a4482586ea001d319c/$FILE/C41+S1+20210601+p992b-992b.pdf

Winter • [December 11, 2023 1:57 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429730)

@JonKnowsNothing, ResearcherZero et al.

> The hidden histories of the conquered tend to show up at awkward moments.

We had our run-in the last few years of crimes of the past.

*   Our Government&King recently apologized for the suffering and death caused by slavery in our South American colonies, and during the slave trade in Africa.
*   Earlier, they did so for the war crimes inflicted on the people of our former colony, Indonesia.
*   Statues of what can today only be called war-criminals and implementers of genocides have been removed or provided with explanations of their hideous crimes.
*   Stolen art and heritage has been returned to places like Indonesia and Sri Lanka, among many others
*   Possessions of Jewish compatriots that were not returned to their heirs after WWII based on reasoning that can only be considered the result of obstinacy and heartlessness had to be paid out to Jewish organizations a few decades ago.
*   Apologies and reparations are made to women whose children were taken because these mothers were not married.

ResearcherZero • [December 11, 2023 2:21 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429732)

As Bruce said, _“To the extent a government improves the overall trust in society, it succeeds. And to the extent a government doesn’t, it fails.”_

“We have mechanisms that induce people to behave in a trustworthy manner, both interpersonally and socially. This, in turn, allows others to be trusting. Which enables trust in society. And that keeps society functioning. The system isn’t perfect—there are always going to be untrustworthy people—but most of us being trustworthy most of the time is good enough.”

This takes a little effort from ourselves. To ensure we don’t jump to conclusions. To also hold those to account that break that trust, through an equitable and fair process. That requires that we support one another when there are cracks in the system, or people abuse their privilege and power, but that we do it in a rational and peaceful manner.

It also requires not walking past those who have fallen, or are unfairly treated. People can be just as rotten sometimes as the very same people they point their finger at and blame. We must accept ourselves when we have wronged others and own up to it.

If we do not — then we ourselves undermine the very trust everyone depends upon.

ResearcherZero • [December 12, 2023 2:22 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429758)

As an example, you might grow up in an oppressive environment, or perhaps work in one. If you internalise it, repression may become oppression, which you might even employ yourself.

Or perhaps your employees? Are they getting a little dangerous to work with?

“When the regional director called me and said, ‘Well, they looked into it and put those guys back on their post,’ I’m like, ‘Are you freaking kidding me right now?’” Bergami said. “My staff were saying to stab me and the captain. I’ve got to worry about our safety.”

[https://www.themarshallproject.org/2023/11/15/illinois-federal-prison-thomson-abuse-thomas-bergami](https://www.themarshallproject.org/2023/11/15/illinois-federal-prison-thomson-abuse-thomas-bergami)

ResearcherZero • [December 13, 2023 2:18 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-429789)

How you might go about establishing a degree of trust with someone of a differing view.

Receptiveness to Opposing Views (with tips on communication)

‘https://journalistsresource.org/politics-and-government/receptive-opposing-views-research/

Anonymous • [December 30, 2023 2:48 PM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-430448)

“Trust is build by the drop and withdrawn in buckets”

James • [April 11, 2025 9:54 AM](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/#comment-444456)

You trusted thebfood supply chain?

[![Image 5: Atom Feed](https://www.schneier.com/wp-content/themes/schneier/assets/images/rss.png) Subscribe to comments on this entry](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html/feed/)

Leave a comment [Cancel reply](http://www.schneier.com/blog/archives/2023/12/ai-and-trust.html#respond)
-------------------------------------------------------------------------------------------------------

[Blog moderation policy](https://www.schneier.com/blog/archives/2024/06/new-blog-moderation-policy.html)

[Login](https://www.schneier.com/wp-login.php?redirect_to=https%3A%2F%2Fwww.schneier.com%2Fblog%2Farchives%2F2023%2F12%2Fai-and-trust.html "Login")
Name

Email

URL:

- [x] Remember personal info?

Fill in the blank: the name of this blog is Schneier on ___________ (required):

Comments: ![Image 6](https://www.schneier.com/wp-content/themes/schneier/assets/images/loader.gif)

**Allowed HTML**<a href="URL"> • <em><cite><i> • <strong><b> • <sub><sup> • <ul><ol><li> • <blockquote><pre>**Markdown Extra** syntax via [https://michelf.ca/projects/php-markdown/extra/](https://michelf.ca/projects/php-markdown/extra/)

Δ

[← Friday Squid Blogging: Strawberry Squid in the Galápagos](https://www.schneier.com/blog/archives/2023/12/friday-squid-blogging-strawberry-squid-in-the-galapagos.html)[AI and Mass Spying →](https://www.schneier.com/blog/archives/2023/12/ai-and-mass-spying.html)

Sidebar photo of Bruce Schneier by Joe MacInnis.

[Powered by WordPress](https://wordpress.com/wp/?partner_domain=www.schneier.com&utm_source=Automattic&utm_medium=colophon&utm_campaign=Concierge%20Referral&utm_term=www.schneier.com)[Hosted by Pressable](https://pressable.com/?utm_source=Automattic&utm_medium=rpc&utm_campaign=Concierge%20Referral&utm_term=concierge)

### About Bruce Schneier

![Image 7](https://www.schneier.com/wp-content/uploads/2019/10/Bruce-Schneier.jpg)
I am a [public-interest technologist](https://public-interest-tech.com/), working at the intersection of security, technology, and people. I've been writing about security issues on my [blog](http://www.schneier.com/) since 2004, and in my monthly [newsletter](http://www.schneier.com/crypto-gram/) since 1998. I'm a fellow and lecturer at Harvard's [Kennedy School](https://www.hks.harvard.edu/faculty/bruce-schneier), a board member of [EFF](https://www.eff.org/), and the Chief of Security Architecture at [Inrupt, Inc.](https://inrupt.com/) This personal website expresses the opinions of none of those organizations.

### Related Entries

*   [AI Coding Assistants Secretly Copying All Code to China](https://www.schneier.com/blog/archives/2026/02/ai-coding-assistants-secretly-copying-all-code-to-china.html)
*   [AIs Are Getting Better at Finding and Exploiting Security Vulnerabilities](https://www.schneier.com/blog/archives/2026/01/ais-are-getting-better-at-finding-and-exploiting-security-vulnerabilities.html)
*   [AIs are Getting Better at Finding and Exploiting Internet Vulnerabilities](https://www.schneier.com/blog/archives/2026/01/ais-are-getting-better-at-finding-and-exploiting-internet-vulnerabilities.html)
*   [Why AI Keeps Falling for Prompt Injection Attacks](https://www.schneier.com/blog/archives/2026/01/why-ai-keeps-falling-for-prompt-injection-attacks.html)
*   [Could ChatGPT Convince You to Buy Something?](https://www.schneier.com/blog/archives/2026/01/could-chatgpt-convince-you-to-buy-something.html)
*   [AI-Powered Surveillance in Schools](https://www.schneier.com/blog/archives/2026/01/ai-powered-surveillance-in-schools.html)

### Featured Essays

*   [Four Ways AI Is Being Used to Strengthen Democracies Worldwide](https://www.schneier.com/essays/archives/2025/11/four-ways-ai-is-being-used-to-strengthen-democracies-worldwide.html)
*   [The CrowdStrike Outage and Market-Driven Brittleness](https://www.schneier.com/essays/archives/2024/07/the-crowdstrike-outage-and-market-driven-brittleness.html)
*   [How Online Privacy Is Like Fishing](https://www.schneier.com/essays/archives/2024/06/how-online-privacy-is-like-fishing.html)
*   [How AI Will Change Democracy](https://www.schneier.com/essays/archives/2024/05/how-ai-will-change-democracy.html)
*   [Seeing Like a Data Structure](https://www.schneier.com/essays/archives/2024/05/seeing-like-a-data-structure.html)
*   [LLMs’ Data-Control Path Insecurity](https://www.schneier.com/essays/archives/2024/05/llms-data-control-path-insecurity.html)
*   [AI and Trust](https://www.schneier.com/essays/archives/2023/12/ai-and-trust.html)
*   [The Value of Encryption](https://www.schneier.com/essays/archives/2016/04/the_value_of_encrypt.html)
*   [The Eternal Value of Privacy](https://www.schneier.com/essays/archives/2006/05/the_eternal_value_of.html)
*   [Terrorists Don't Do Movie Plots](https://www.schneier.com/essays/archives/2005/09/terrorists_dont_do_m.html)

[More Essays](https://www.schneier.com/essays/)

### Blog Archives

*   [Archive by Month](https://www.schneier.com/blog/calendar.html/)
*   [100 Latest Comments](https://www.schneier.com/blog/newcomments.html/)

#### Blog Tags

*   [3d printers](https://www.schneier.com/tag/3d-printers/)
*   [9/11](https://www.schneier.com/tag/9-11/)
*   [A Hacker's Mind](https://www.schneier.com/tag/a-hackers-mind/)
*   [Aaron Swartz](https://www.schneier.com/tag/aaron-swartz/)
*   [academic](https://www.schneier.com/tag/academic/)
*   [academic papers](https://www.schneier.com/tag/academic-papers/)
*   [accountability](https://www.schneier.com/tag/accountability/)
*   [ACLU](https://www.schneier.com/tag/aclu/)
*   [activism](https://www.schneier.com/tag/activism/)
*   [Adobe](https://www.schneier.com/tag/adobe/)
*   [advanced persistent threats](https://www.schneier.com/tag/advanced-persistent-threats/)
*   [adware](https://www.schneier.com/tag/adware/)
*   [AES](https://www.schneier.com/tag/aes/)
*   [Afghanistan](https://www.schneier.com/tag/afghanistan/)
*   [AI](https://www.schneier.com/tag/ai/)
*   [air marshals](https://www.schneier.com/tag/air-marshals/)
*   [air travel](https://www.schneier.com/tag/air-travel/)
*   [airgaps](https://www.schneier.com/tag/airgaps/)
*   [al Qaeda](https://www.schneier.com/tag/al-qaeda/)
*   [alarms](https://www.schneier.com/tag/alarms/)
*   [algorithms](https://www.schneier.com/tag/algorithms/)
*   [alibis](https://www.schneier.com/tag/alibis/)
*   [Amazon](https://www.schneier.com/tag/amazon/)
*   [Android](https://www.schneier.com/tag/android/)
*   [anonymity](https://www.schneier.com/tag/anonymity/)
*   [Anonymous](https://www.schneier.com/tag/anonymous/)
*   [antivirus](https://www.schneier.com/tag/antivirus/)
*   [Apache](https://www.schneier.com/tag/apache/)
*   [Apple](https://www.schneier.com/tag/apple/)
*   [Applied Cryptography](https://www.schneier.com/tag/applied-cryptography/)

[More Tags](https://www.schneier.com/blog/tags.html/)

### Latest Book

[![Image 8: Rewiring Democracy](https://www.schneier.com/wp-content/uploads/2025/05/book-rewiring-200w.jpg)](https://www.schneier.com/books/rewiring-democracy/)
[More Books](https://www.schneier.com/books/)

[![Image 9: Support Bloggers' Rights!](https://www.schneier.com/wp-content/themes/schneier/assets/images/join-eff@2x.png)](https://www.eff.org/issues/bloggers/legal/join)[![Image 10: Defend Privacy--Support Epic](https://www.schneier.com/wp-content/themes/schneier/assets/images/support-epic@2x.png)](https://epic.org/donate-to-epic/)

*   [Blog](https://www.schneier.com/)
*   [Newsletter](https://www.schneier.com/crypto-gram/)
*   [Books](https://www.schneier.com/books/)
*   [Essays](https://www.schneier.com/essays/)
*   [News](https://www.schneier.com/news/)
*   [Talks](https://www.schneier.com/talks/)
*   [Academic](https://www.schneier.com/academic/)
*   [About Me](https://www.schneier.com/blog/about/)

![Image 11](https://pixel.wp.com/g.gif?v=ext&blog=182601345&post=68156&tz=-5&srv=www.schneier.com&hp=atomic&ac=3&amp=0&j=1%3A15.5-beta&host=www.schneier.com&ref=&rand=0.9411606865531409)

---
*自动采集于 2026-02-03*
