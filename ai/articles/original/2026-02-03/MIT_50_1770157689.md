---
title: "Inside the marketplace powering bespoke AI deepfakes of real women"
url: "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/"
source: "MIT Tech Review"
date: 2026-02-03
score: 50
---

# Inside the marketplace powering bespoke AI deepfakes of real women

**来源**: [MIT Tech Review](https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/) | **热度**: 50

## 原文内容

Title: Inside the marketplace powering bespoke AI deepfakes of real women

URL Source: http://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/

Published Time: 2026-01-30T11:32:31-05:00

Markdown Content:
Civitai—an online marketplace for buying and selling AI-generated content, backed by the venture capital firm Andreessen Horowitz—is letting users buy custom instruction files for generating celebrity deepfakes. Some of these files were specifically designed to make pornographic images banned by the site, a new analysis has found.

The study, from researchers at Stanford and Indiana University, looked at people’s requests for content on the site, called “bounties.” The researchers found that between mid-2023 and the end of 2024, most bounties asked for animated content—but a significant portion were for deepfakes of real people, and 90% of these deepfake requests targeted women. (Their [findings](https://arxiv.org/pdf/2601.09117) have not yet been peer reviewed.)

The debate around deepfakes, as illustrated by the [recent backlash](https://www.nytimes.com/2026/01/26/business/european-union-x-grok-ai-images-musk.html) to explicit images on the X-owned chatbot Grok, has revolved around what platforms should do to block such content. Civitai’s situation is a little more complicated. Its marketplace includes actual images, videos, and models, but it also lets individuals buy and sell instruction files called LoRAs that can coach mainstream AI models like Stable Diffusion into generating content they were not trained to produce. Users can then combine these files with other tools to make deepfakes that are graphic or sexual. The researchers found that 86% of deepfake requests on Civitai were for LoRAs.

In these bounties, users requested “high quality” models to generate images of public figures like the influencer Charli D’Amelio or the singer Gracie Abrams, often linking to their social media profiles so their images could be grabbed from the web. Some requests specified a desire for models that generated the individual’s entire body, accurately captured their tattoos, or allowed hair color to be changed. Some requests targeted several women in specific niches, like artists who record ASMR videos. One request was for a deepfake of a woman said to be the user’s wife. Anyone on the site could offer up AI models they worked on for the task, and the best submissions received payment—anywhere from $0.50 to $5. And nearly 92% of the deepfake bounties were awarded.

Neither Civitai nor Andreessen Horowitz responded to requests for comment.

It’s possible that people buy these LoRAs to make deepfakes that aren’t sexually explicit (though they’d still violate Civitai’s terms of use, and they’d still be ethically fraught). But Civitai also offers [educational resources](https://civitai.com/articles) on how to use external tools to further customize the outputs of image generators—for example, by changing someone’s pose. The site also hosts user-written [articles](https://civitai.com/articles) with details on how to instruct models to generate pornography. The researchers found that the amount of porn on the platform has gone up, and that the majority of requests each week are now for NSFW content.

“Not only does Civitai provide the infrastructure that facilitates these issues; they also explicitly teach their users how to utilize them,” says Matthew DeVerna, a postdoctoral researcher at Stanford’s Cyber Policy Center and one of the study’s leaders.

The company used to ban only sexually explicit deepfakes of real people, but in May 2025 it announced it would [ban](https://civitai.com/articles/15022) all deepfake content. Nonetheless, countless requests for deepfakes submitted before this ban now remain live on the site, and many of the winning submissions fulfilling those requests remain available for purchase, _MIT Technology Review_ confirmed.

“I believe the approach that they’re trying to take is to sort of do as little as possible, such that they can foster as much—I guess they would call it—creativity on the platform,” DeVerna says.

Users buy LoRAs with the site’s online currency, called Buzz, which is purchased with real money. In May 2025, Civita’s credit card processor [cut off](https://civitai.com/articles/14945/credit-card-payments-pausing-may-23-2025) the company because of its ongoing [problem](https://www.404media.co/inside-the-ai-porn-marketplace-where-everything-and-everyone-is-for-sale/) with nonconsensual content. To pay for explicit content, users must now use gift cards or cryptocurrency to [buy](https://education.civitai.com/civitais-guide-to-on-site-currency-buzz-%E2%9A%A1/) Buzz; the company offers a different scrip for non-explicit content.

Civitai automatically tags bounties requesting deepfakes and lists a way for the person featured in the content to manually request its takedown. This system means that Civitai has a reasonably

---
*自动采集于 2026-02-03*
