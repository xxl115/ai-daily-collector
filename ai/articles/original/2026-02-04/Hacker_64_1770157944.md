---
title: "Bruce Schneier: AI and the scaling of betrayal (2023)"
url: "https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html"
source: "Hacker News"
date: 2026-02-04
score: 64
---

# Bruce Schneier: AI and the scaling of betrayal (2023)

**来源**: [Hacker News](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html) | **热度**: 64

## 原文内容

Title: AI and Trust

URL Source: http://www.schneier.com/blog/archives/2023/12/ai-and-trust.html

Published Time: 2023-12-04T12:05:33+00:00

Markdown Content:
AI and Trust - Schneier on Security
===============

[Schneier on Security](https://www.schneier.com/)
=================================================

[Menu](http://www.schneier.com/blog/archives/2023/12/ai-and-trust.html#)

*   [Blog](https://www.schneier.com/)
*   [Newsletter](https://www.schneier.com/crypto-gram/)
*   [Books](https://www.schneier.com/books/)
*   [Essays](https://www.schneier.com/essays/)
*   [News](https://www.schneier.com/news/)
*   [Talks](https://www.schneier.com/talks/)
*   [Academic](https://www.schneier.com/academic/)
*   [About Me](https://www.schneier.com/blog/about/)

### Search

_Powered by [DuckDuckGo](https://duckduckgo.com/)_

Blog Essays Whole site 

### Subscribe

[![Image 1: Atom](https://www.schneier.com/wp-content/uploads/2019/10/rss-32px.png)](https://www.schneier.com/feed/atom/)[![Image 2: Facebook](https://www.schneier.com/wp-content/uploads/2019/10/facebook-32px.png)](https://www.facebook.com/bruce.schneier)[![Image 3: Twitter](https://www.schneier.com/wp-content/uploads/2019/10/twitter-32px.png)](https://twitter.com/schneierblog)[![Image 4: Email](https://www.schneier.com/wp-content/uploads/2019/10/email-32px.png)](https://www.schneier.com/crypto-gram)

[Home](https://www.schneier.com/)[Blog](https://www.schneier.com/blog/archives/)

AI and Trust
------------

I trusted a lot today. I trusted my phone to wake me on time. I trusted Uber to arrange a taxi for me, and the driver to get me to the airport safely. I trusted thousands of other drivers on the road not to ram my car on the way. At the airport, I trusted ticket agents and maintenance engineers and everyone else who keeps airlines operating. And the pilot of the plane I flew in. And thousands of other people at the airport and on the plane, any of which could have attacked me. And all the people that prepared and served my breakfast, and the entire food supply chain—any of them could have poisoned me. When I landed here, I trusted thousands more people: at the airport, on the road, in this building, in this room. And that was all before 10:30 this morning.

Trust is essential to society. Humans as a species are trusting. We are all sitting here, mostly strangers, confident that nobody will attack us. If we were a roomful of chimpanzees, this would be impossible. We trust many thousands of times a day. Society can’t function without it. And that we don’t even think about it is a measure of how well it all works.

In this talk, I am going to make several arguments. One, that there are two different kinds of trust—interpersonal trust and social trust—and that we regularly confuse them. Two, that the confusion will increase with artificial intelligence. We will make a fundamental category error. We will think of AIs as friends when they’re really just services. Three, that the corporations controlling AI systems will take advantage of our confusion to take advantage of us. They will not be trustworthy. And four, that it is the role of government to create trust in society. And therefore, it is their role to create an environment for trustworthy AI. And that means regulation. Not regulating AI, but regulating the organizations that control and use AI.

Okay, so let’s back up and take that all a lot slower. Trust is a complicated concept, and the word is overloaded with many meanings. There’s personal and intimate trust. When we say that we trust a friend, it is less about their specific actions and more about them as a person. It’s a general reliance that they will behave in a trustworthy manner. We trust their intentions, and know that those intentions will inform their actions. Let’s call this “interpersonal trust.”

There’s also the less intimate, less personal trust. We might not know someone personally, or know their motivations—but we can trust their behavior. We don’t know whether or not someone wants to steal, but maybe we can trust that they won’t. It’s really more about reliability and predictability. We’ll call this “social trust.” It’s the ability to trust strangers.

Interpersonal trust and social trust are both essential in society today. This is how it works. We have mechanisms that induce people to behave in a trustworthy manner, both interpersonally and socially. This, in turn, allows others to be trusting. Which enables trust in society. And that keeps society functioning. The system isn’t perfect—there are always going to be untrustworthy people—but most of us being trustworthy most of the time is good enough.

I wrote about this in 2012 in a book called [_Liars and Outliers_](https://www.schneier.com/books/liars-and-outliers/). I wrote about four systems for enabling trust: our innate morals, concern about our reputations, the laws we live under, and security technologies that constrain our behavior. I wrote about how the first two are

---
*自动采集于 2026-02-04 06:32:25 (北京时间)*
