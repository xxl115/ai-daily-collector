"""
æ ‡ç­¾æå–å·¥å…·
ä»æ–‡ç« æ ‡é¢˜å’Œæ‘˜è¦ä¸­æå–æ ‡ç­¾
"""
import re
from typing import List


class TagExtractor:
    """æ ‡ç­¾æå–å™¨"""

    # é¢„å®šä¹‰æ ‡ç­¾åº“ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    PREDEFINED_TAGS = {
        'llm': {'keywords': ['llm', 'å¤§æ¨¡å‹', 'large language model'], 'emoji': 'ğŸ¤–'},
        'gpt-4': {'keywords': ['gpt-4', 'gpt4', 'gpt 4'], 'emoji': 'ğŸ§ '},
        'gpt': {'keywords': ['gpt', 'chatgpt'], 'emoji': 'ğŸ’¬'},
        'claude': {'keywords': ['claude', 'anthropic'], 'emoji': 'ğŸ¯'},
        'aiç»˜ç”»': {'keywords': ['aiç»˜ç”»', 'image generation', 'diffusion', 'midjourney', 'stable diffusion', 'dalle'], 'emoji': 'ğŸ¨'},
        'video': {'keywords': ['è§†é¢‘', 'video', 'movie', 'animation'], 'emoji': 'ğŸ¬'},
        'ç ”ç©¶': {'keywords': ['ç ”ç©¶', 'research', 'paper', 'study', 'arxiv'], 'emoji': 'ğŸ“š'},
        'å­¦æœ¯': {'keywords': ['å­¦æœ¯', 'academic', 'è®ºæ–‡', 'conference'], 'emoji': 'ğŸ“'},
        'å¼€æº': {'keywords': ['å¼€æº', 'open source', 'github', 'apache', 'mit'], 'emoji': 'ğŸ”“'},
        'äº§å“': {'keywords': ['äº§å“', 'product', 'tool', 'app', 'application'], 'emoji': 'ğŸ“¦'},
        'äº§å“å‘å¸ƒ': {'keywords': ['å‘å¸ƒ', 'release', 'launch', 'v6', 'v5', 'version'], 'emoji': 'ğŸš€'},
        'å·¥å…·': {'keywords': ['å·¥å…·', 'tool', 'framework', 'library', 'sdk', 'api'], 'emoji': 'ğŸ› ï¸'},
        'å·¥å…·è¯„æµ‹': {'keywords': ['è¯„æµ‹', 'review', 'comparison', 'compare', 'benchmark'], 'emoji': 'ğŸ“Š'},
        'è¡Œä¸šåŠ¨æ€': {'keywords': ['åŠ¨æ€', 'news', 'update', 'è¶‹åŠ¿', 'trend'], 'emoji': 'ğŸ“ˆ'},
        'å¤šæ¨¡æ€': {'keywords': ['å¤šæ¨¡æ€', 'multimodal', 'vision', 'text-to-image'], 'emoji': 'ğŸ‘ï¸'},
        'agent': {'keywords': ['agent', 'mcp', 'a2a', 'workflow'], 'emoji': 'ğŸ¤'},
        'å®‰å…¨': {'keywords': ['å®‰å…¨', 'security', 'vulnerability', 'attack', 'defense'], 'emoji': 'ğŸ”’'},
        'google': {'keywords': ['google', 'gemini', 'bard'], 'emoji': 'ğŸ”'},
        'nvidia': {'keywords': ['nvidia', 'gpu', 'cuda', 'h100', 'a100'], 'emoji': 'ğŸ’»'},
        'cursor': {'keywords': ['cursor', 'ide', 'editor'], 'emoji': 'âŒ¨ï¸'},
        'copilot': {'keywords': ['copilot', 'github copilot'], 'emoji': 'âœˆï¸'},
    }

    # éœ€è¦æ’é™¤çš„å¸¸è§è¯
    STOP_WORDS = {
        'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
        'should', 'may', 'might', 'must', 'shall', 'can', 'need', 'dare',
        'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',
        'into', 'through', 'during', 'before', 'after', 'above', 'below',
        'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over',
        'under', 'again', 'further', 'then', 'once', 'here', 'there',
        'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each',
        'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor',
        'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',
        's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'çš„', 'äº†', 'æ˜¯',
    }

    def extract(self, title: str, summary: str, source: str, max_tags: int = 5) -> List[str]:
        """
        æå–æ ‡ç­¾

        Args:
            title: æ–‡ç« æ ‡é¢˜
            summary: æ–‡ç« æ‘˜è¦
            source: æ¥æº
            max_tags: æœ€å¤§æ ‡ç­¾æ•°é‡

        Returns:
            æ ‡ç­¾åˆ—è¡¨
        """
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
        text = f"{title} {summary} {source}".lower()

        tags = set()
        matched_keywords = set()  # è®°å½•å·²åŒ¹é…çš„å…³é”®è¯

        # 1. æŒ‰ä¼˜å…ˆçº§åŒ¹é…é¢„å®šä¹‰æ ‡ç­¾
        # æŒ‰æ ‡ç­¾åç§°é•¿åº¦å€’åºï¼ˆä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„æ ‡ç­¾ï¼‰
        sorted_tags = sorted(
            self.PREDEFINED_TAGS.items(),
            key=lambda x: len(x[0]),
            reverse=True
        )

        for tag_key, tag_info in sorted_tags:
            for keyword in tag_info['keywords']:
                if keyword in text:
                    display_name = tag_key.upper() if tag_key.replace('-', '').isalpha() else tag_key

                    # æ£€æŸ¥æ˜¯å¦ä¸å·²æ·»åŠ çš„æ ‡ç­¾å†²çªï¼ˆé¿å…é‡å åŒ¹é…ï¼‰
                    # ä¾‹å¦‚ï¼šå¦‚æœå·²æ·»åŠ  "gpt-4"ï¼Œåˆ™è·³è¿‡ "gpt"
                    is_duplicate = False
                    for existing in tags:
                        existing_normalized = existing.lower().replace('-', '').replace(' ', '')
                        display_normalized = display_name.lower().replace('-', '').replace(' ', '')
                        # å¦‚æœç°æœ‰æ ‡ç­¾åŒ…å«å½“å‰æ ‡ç­¾ï¼Œè·³è¿‡ï¼ˆå¦‚ "GPT-4" åŒ…å« "GPT"ï¼‰
                        if existing_normalized in display_normalized or \
                           display_normalized in existing_normalized:
                            is_duplicate = True
                            break

                    if is_duplicate:
                        continue

                    tags.add(display_name)
                    matched_keywords.add(keyword)
                    break

        # 2. ä»æ–‡æœ¬ä¸­æå–é¢å¤–å…³é”®è¯ï¼ˆæ’é™¤å·²åŒ¹é…çš„ï¼‰
        extra_keywords = self._extract_keywords(text)
        for keyword in extra_keywords[:5]:
            display_keyword = keyword.upper() if keyword.replace('-', '').isalpha() else keyword

            # æ£€æŸ¥æ˜¯å¦ä¸å·²é€‰æ ‡ç­¾å†²çª
            is_duplicate = False
            for existing in tags:
                if existing.lower() == display_keyword.lower():
                    is_duplicate = True
                    break

            if not is_duplicate and len(keyword) > 2:
                tags.add(display_keyword)

            if len(tags) >= max_tags:
                break

        # 3. è½¬æ¢ä¸ºåˆ—è¡¨å¹¶é™åˆ¶æ•°é‡
        tag_list = list(tags)

        # ä¼˜å…ˆçº§æ’åº
        priority_tags = ['LLM', 'GPT-4', 'AIç»˜ç”»', 'CLAUDE', 'å¼€æº', 'äº§å“å‘å¸ƒ', 'ç ”ç©¶', 'AGENT', 'VIDEO']
        tag_list.sort(key=lambda x: 0 if x.upper() in [t.upper() for t in priority_tags] else 1)

        return tag_list[:max_tags]

    def _extract_keywords(self, text: str, min_length: int = 3) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯

        Args:
            text: è¾“å…¥æ–‡æœ¬
            min_length: æœ€å°è¯é•¿

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        cleaned = re.sub(r'[^\w\s-]', ' ', text)

        # åˆ†è¯
        words = re.findall(r'\b[\w-]+\b', cleaned.lower())

        # è¿‡æ»¤åœç”¨è¯
        keywords = [word for word in words if word not in self.STOP_WORDS and len(word) >= min_length]

        # ç»Ÿè®¡è¯é¢‘
        word_counts = {}
        for word in keywords:
            word_counts[word] = word_counts.get(word, 0) + 1

        # æŒ‰é¢‘ç‡æ’åº
        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

        # è¿”å›å‰ 10 ä¸ªé«˜é¢‘è¯
        return [word for word, count in sorted_words[:10]]

    def get_popular_tags(self, limit: int = 10) -> List[dict]:
        """
        è·å–çƒ­é—¨æ ‡ç­¾åˆ—è¡¨

        Args:
            limit: è¿”å›æ•°é‡

        Returns:
            çƒ­é—¨æ ‡ç­¾åˆ—è¡¨
        """
        tags = []
        for tag_key, tag_info in list(self.PREDEFINED_TAGS.items())[:limit]:
            tags.append({
                'id': tag_key,
                'name': tag_key.upper() if tag_key.replace('-', '').isalpha() else tag_key,
                'emoji': tag_info['emoji'],
                'keywords': tag_info['keywords']
            })

        return tags

    def search_tags(self, query: str, limit: int = 5) -> List[dict]:
        """
        æœç´¢æ ‡ç­¾

        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: è¿”å›æ•°é‡

        Returns:
            åŒ¹é…çš„æ ‡ç­¾åˆ—è¡¨
        """
        query = query.lower()
        results = []

        for tag_key, tag_info in self.PREDEFINED_TAGS.items():
            # æœç´¢æ ‡ç­¾åç§°
            if query in tag_key:
                results.append({
                    'id': tag_key,
                    'name': tag_key.upper() if tag_key.replace('-', '').isalpha() else tag_key,
                    'emoji': tag_info['emoji']
                })
                continue

            # æœç´¢å…³é”®è¯
            for keyword in tag_info['keywords']:
                if query in keyword:
                    results.append({
                        'id': tag_key,
                        'name': tag_key.upper() if tag_key.replace('-', '').isalpha() else tag_key,
                        'emoji': tag_info['emoji']
                    })
                    break

        return results[:limit]
