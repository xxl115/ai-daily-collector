# AI Daily Collector - ç»Ÿä¸€é…ç½®
# æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–

from pathlib import Path
from typing import Optional
import os

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent

# æ•°æ®ç›®å½•
DATA_DIR = Path(os.environ.get("DATA_DIR", PROJECT_ROOT / "data"))

# API é…ç½®
class APIConfig:
    host = os.environ.get("API_HOST", "0.0.0.0")
    port = int(os.environ.get("API_PORT", 8000))
    debug = os.environ.get("API_DEBUG", "false").lower() == "true"
    cors_origins = os.environ.get("API_CORS_ORIGINS", "*").split(",")


# æ™ºè°± AI é…ç½®
class ZhipuConfig:
    api_key = os.environ.get("ZAI_API_KEY", "")
    api_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    model = os.environ.get("ZAI_MODEL", "glm-4")
    max_tokens = int(os.environ.get("ZAI_MAX_TOKENS", 500))
    temperature = float(os.environ.get("ZAI_TEMPERATURE", 0.7))


# Notion é…ç½®
class NotionConfig:
    api_key = os.environ.get("NOTION_API_KEY", "")
    parent_page_id = os.environ.get("NOTION_PARENT_PAGE_ID", "")


# GitHub é…ç½®
class GitHubConfig:
    repo_url = os.environ.get("GITHUB_REPO_URL", "https://github.com/xxl115/ai-daily-collector")
    commit_message = os.environ.get("GITHUB_COMMIT_MSG", "ğŸ“… Daily update {date}")


# é‡‡é›†é…ç½®
class CrawlerConfig:
    articles_hours_back = int(os.environ.get("ARTICLES_HOURS_BACK", 24))
    filter_ai_only = os.environ.get("FILTER_AI_ONLY", "true").lower() == "true"
    max_articles_per_source = int(os.environ.get("MAX_ARTICLES", 30))
    request_timeout = int(os.environ.get("REQUEST_TIMEOUT", 30))
    retry_times = int(os.environ.get("RETRY_TIMES", 3))


# æ—¥æŠ¥é…ç½®
class ReportConfig:
    focus_article_limit = 1
    category_article_limit = 5
    summary_length = {
        "focus": 150,
        "normal": 100
    }


# æ—¥å¿—é…ç½®
class LogConfig:
    level = os.environ.get("LOG_LEVEL", "INFO")
    format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file_path = DATA_DIR / "logs" / "app.log"


# å¯¼å‡ºé…ç½®å®ä¾‹
config = type("Config", (), {
    "api": APIConfig,
    "zhipu": ZhipuConfig,
    "notion": NotionConfig,
    "github": GitHubConfig,
    "crawler": CrawlerConfig,
    "report": ReportConfig,
    "log": LogConfig,
    "data_dir": DATA_DIR,
    "project_root": PROJECT_ROOT
})()


def get_source_config(name: str) -> Optional[dict]:
    """è·å–æŒ‡å®š RSS æºé…ç½®"""
    import yaml
    config_path = PROJECT_ROOT / "config" / "sources.yaml"
    
    if not config_path.exists():
        return None
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config_data = yaml.safe_load(f)
    
    for source in config_data.get('sources', []):
        if source.get('name') == name:
            return source
    
    return None
