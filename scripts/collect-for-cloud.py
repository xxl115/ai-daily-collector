#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Daily Collector - äº‘ç«¯é‡‡é›†è¾…åŠ©è„šæœ¬

ä» sources.yaml è¯»å–é…ç½®ï¼Œè¾“å‡º bash å¯ç”¨çš„æ•°æ®æ ¼å¼

è¾“å‡ºæ ¼å¼:
SOURCE|TITLE|URL|SCORE|AUTHOR

ç”¨æ³•:
    python scripts/collect-for-cloud.py

è¾“å‡ºç¤ºä¾‹:
    Hacker News|Agent Skills|https://example.com|100|john
    GitHub|awesome-ai|https://github.com/...|500|octocat
"""

import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from utils.logger import setup_logger, get_logger
from utils.filter import keyword_filter

# å¯¼å…¥ fetchers
from fetchers import (
    fetch_by_config,
)

# å¯¼å…¥é…ç½®
import yaml


def load_sources_config():
    """åŠ è½½ sources.yaml é…ç½®"""
    config_path = project_root / "config" / "sources.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def collect_from_sources():
    """ä»é…ç½®çš„æ•°æ®æºé‡‡é›†"""
    sources_config = load_sources_config()
    all_articles = []

    for source in sources_config.get('sources', []):
        if not source.get('enabled', False):
            continue

        source_name = source.get('name', 'Unknown')
        source_type = source.get('type', '')

        try:
            items = fetch_by_config(source)
            if items:
                all_articles.extend(items)
                print(f"âœ… {source_name}: {len(items)} æ¡", file=sys.stderr)
            else:
                print(f"âš ï¸ {source_name}: æ— æ•°æ®", file=sys.stderr)
        except Exception as e:
            print(f"âŒ {source_name}: {e}", file=sys.stderr)

    return all_articles


def filter_articles(articles):
    """è¿‡æ»¤æ–‡ç« """
    if not articles:
        return []

    matched, _ = keyword_filter.filter_articles(
        articles,
        title_field="title",
    )

    return matched


def output_for_bash(articles):
    """è¾“å‡º bash å¯ç”¨çš„æ ¼å¼"""
    # æŒ‰çƒ­åº¦æ’åº
    articles.sort(key=lambda x: x.get('hot_score', 0), reverse=True)

    for article in articles:
        source = article.get('source', 'Unknown')
        title = article.get('title', '').replace('|', '\\|').replace('\n', ' ')
        url = article.get('url', '')
        score = article.get('hot_score', 0)
        author = article.get('author', article.get('source_id', ''))

        # è¾“å‡º: SOURCE|TITLE|URL|SCORE|AUTHOR
        print(f"{source}|{title}|{url}|{score}|{author}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“¥ å¼€å§‹é‡‡é›†...", file=sys.stderr)

    # é‡‡é›†æ•°æ®
    articles = collect_from_sources()
    print(f"\nğŸ“Š æ€»è®¡é‡‡é›†: {len(articles)} æ¡", file=sys.stderr)

    # è¿‡æ»¤
    articles = filter_articles(articles)
    print(f"ğŸ” è¿‡æ»¤å: {len(articles)} æ¡", file=sys.stderr)

    # è¾“å‡º
    output_for_bash(articles)


if __name__ == "__main__":
    main()
