#!/bin/bash
# AI Daily Collector - äº‘ç«¯å¢žå¼ºç‰ˆ (ä½¿ç”¨ jina.ai æå–åŽŸæ–‡)

DATE=$(date +%Y-%m-%d)
OUTPUT_DIR="ai/articles/original/${DATE}"

echo "============================================"
echo "AI Daily Collector (Cloud Enhanced)"
echo "æ—¥æœŸ: $DATE"
echo "============================================"
echo ""

mkdir -p "$OUTPUT_DIR"
TOTAL_COUNT=0
KEYWORDS="AI|Claude|llm|agent|cursor|programming|developer|machine learning|software"

# æå–æ–‡ç« å†…å®¹å‡½æ•° (ä½¿ç”¨ jina.ai)
extract_content() {
    local URL="$1"
    # ç§»é™¤åè®®å¤´ï¼Œåªä¿ç•™åŸŸåå’Œè·¯å¾„
    local CLEAN_URL=$(echo "$URL" | sed 's|https://||' | sed 's|http://||')
    local CONTENT=$(curl -s --max-time 15 "https://r.jina.ai/http://${CLEAN_URL}" 2>/dev/null)
    echo "$CONTENT"
}

# ========== 1. Hacker News ==========
echo "ðŸ“¥ é‡‡é›† Hacker News..."
HN_API="https://hacker-news.firebaseio.com/v0"
HN_COUNT=0

IDS=$(curl -s --connect-timeout 10 "${HN_API}/topstories.json" 2>/dev/null | head -30 | tr ',' '\n')

for ID in $IDS; do
    STORY=$(curl -s --connect-timeout 5 "${HN_API}/item/${ID}.json" 2>/dev/null)
    [ -z "$STORY" ] && continue
    
    TITLE=$(echo "$STORY" | jq -r '.title' 2>/dev/null)
    URL=$(echo "$STORY" | jq -r '.url' 2>/dev/null)
    SCORE=$(echo "$STORY" | jq -r '.score' 2>/dev/null)
    BY=$(echo "$STORY" | jq -r '.by' 2>/dev/null)
    
    if echo "$TITLE" | grep -qiE "$KEYWORDS"; then
        ((HN_COUNT++))
        TOTAL_COUNT=$((TOTAL_COUNT + 1))
        TIMESTAMP=$(date +%s)
        FILENAME="HN_${SCORE}_${ID}.md"
        
        # æå–åŽŸæ–‡
        CONTENT=""
        if [ -n "$URL" ]; then
            CONTENT=$(extract_content "$URL")
        fi
        
        cat > "$OUTPUT_DIR/$FILENAME" << EOF
---
title: "$TITLE"
url: "$URL"
source: "Hacker News"
date: "$DATE"
score: "$SCORE"
author: "$BY"
---

# $TITLE

**æ¥æº**: [Hacker News](https://news.ycombinator.com/item?id=$ID) | **è¯„åˆ†**: $SCORE | **ä½œè€…**: @$BY

## åŽŸæ–‡å†…å®¹

$CONTENT

---
*è‡ªåŠ¨é‡‡é›†äºŽ $DATE*
EOF
        echo "   âœ… [HN] $TITLE"
    fi
    [ $HN_COUNT -ge 6 ] && break
done
echo "   â†’ Hacker News: $HN_COUNT æ¡"

# ========== 2. GitHub ==========
echo ""
echo "ðŸ“¥ é‡‡é›† GitHub..."

GH_TOKEN="$GITHUB_TOKEN"
GH_COUNT=0

if [ -n "$GH_TOKEN" ]; then
    GH_DATA=$(curl -s --connect-timeout 20 \
        -H "Authorization: Bearer $GH_TOKEN" \
        "https://api.github.com/search/repositories?q=AI+agent+cursor&sort=stars&per_page=8" 2>/dev/null)
    
    if echo "$GH_DATA" | grep -q '"items"'; then
        for i in 0 1 2 3 4 5 6 7; do
            NAME=$(echo "$GH_DATA" | jq -r ".items[$i].name // empty" 2>/dev/null)
            FULL_NAME=$(echo "$GH_DATA" | jq -r ".items[$i].full_name // empty" 2>/dev/null)
            DESC=$(echo "$GH_DATA" | jq -r ".items[$i].description // empty" 2>/dev/null)
            STARS=$(echo "$GH_DATA" | jq -r ".items[$i].stargazers_count // 0" 2>/dev/null)
            URL=$(echo "$GH_DATA" | jq -r ".items[$i].html_url // empty" 2>/dev/null)
            LANG=$(echo "$GH_DATA" | jq -r ".items[$i].language // empty" 2>/dev/null)
            
            if [ -n "$NAME" ] && [ -n "$URL" ] && [ "$NAME" != "null" ]; then
                ((GH_COUNT++))
                TOTAL_COUNT=$((TOTAL_COUNT + 1))
                TIMESTAMP=$(date +%s)
                FILENAME="GH_${STARS}_${TIMESTAMP}_${i}.md"
                
                # æå– README å†…å®¹
                CONTENT=""
                if [ -n "$URL" ]; then
                    CONTENT=$(extract_content "$URL")
                fi
                
                cat > "$OUTPUT_DIR/$FILENAME" << EOF
---
title: "$NAME"
url: "$URL"
source: "GitHub"
date: "$DATE"
score: "$STARS"
author: "$FULL_NAME"
---

# $NAME

**æ¥æº**: [GitHub]($URL) | **â­ Stars**: $STARS | **è¯­è¨€**: $LANG

## é¡¹ç›®æè¿°

$DESC

## åŽŸæ–‡ README

$CONTENT

---
*è‡ªåŠ¨é‡‡é›†äºŽ $DATE*
EOF
                echo "   âœ… [GH] â­$STARS $NAME"
            fi
        done
    fi
fi
echo "   â†’ GitHub: $GH_COUNT æ¡"

# ========== 3. Hugging Face ==========
echo ""
echo "ðŸ“¥ é‡‡é›† Hugging Face..."
HF_DATA=$(curl -s --connect-timeout 15 "https://huggingface.co/blog/feed.xml" 2>/dev/null)
HF_COUNT=0

if [ -n "$HF_DATA" ] && echo "$HF_DATA" | grep -q '<item>'; then
    for i in 0 1 2 3 4; do
        TITLE=$(echo "$HF_DATA" | grep -oP '<title>\K[^<]+' 2>/dev/null | sed -n "$((i+2))p")
        LINK=$(echo "$HF_DATA" | grep -oP '<link>\K[^<]+' 2>/dev/null | sed -n "$((i+1))p")
        
        if [ -n "$TITLE" ] && [ -n "$LINK" ]; then
            ((HF_COUNT++))
            TOTAL_COUNT=$((TOTAL_COUNT + 1))
            TIMESTAMP=$(date +%s)
            FILENAME="HF_${TIMESTAMP}_${i}.md"
            
            # æå–å†…å®¹
            CONTENT=$(extract_content "$LINK")
            
            cat > "$OUTPUT_DIR/$FILENAME" << EOF
---
title: "$TITLE"
url: "$LINK"
source: "Hugging Face"
date: "$DATE"
---

# $TITLE

**æ¥æº**: [Hugging Face]($LINK)

## åŽŸæ–‡å†…å®¹

$CONTENT

---
*è‡ªåŠ¨é‡‡é›†äºŽ $DATE*
EOF
            echo "   âœ… [HF] $TITLE"
        fi
    done
fi
echo "   â†’ Hugging Face: $HF_COUNT æ¡"

# ========== 4. MIT Technology Review ==========
echo ""
echo "ðŸ“¥ é‡‡é›† MIT Technology Review..."
MIT_DATA=$(curl -s --connect-timeout 15 "https://www.technologyreview.com/feed/" 2>/dev/null)
MIT_COUNT=0

if [ -n "$MIT_DATA" ] && echo "$MIT_DATA" | grep -q '<item>'; then
    for i in 0 1 2 3 4; do
        TITLE=$(echo "$MIT_DATA" | grep -oP '<title>\K[^<]+' 2>/dev/null | sed -n "$((i+2))p")
        LINK=$(echo "$MIT_DATA" | grep -oP '<link>\K[^<]+' 2>/dev/null | sed -n "$((i+1))p")
        
        if [ -n "$TITLE" ] && [ -n "$LINK" ]; then
            ((MIT_COUNT++))
            TOTAL_COUNT=$((TOTAL_COUNT + 1))
            TIMESTAMP=$(date +%s)
            FILENAME="MIT_${TIMESTAMP}_${i}.md"
            
            # æå–å†…å®¹
            CONTENT=$(extract_content "$LINK")
            
            cat > "$OUTPUT_DIR/$FILENAME" << EOF
---
title: "$TITLE"
url: "$LINK"
source: "MIT Technology Review"
date: "$DATE"
---

# $TITLE

**æ¥æº**: [MIT Technology Review]($LINK)

## åŽŸæ–‡å†…å®¹

$CONTENT

---
*è‡ªåŠ¨é‡‡é›†äºŽ $DATE*
EOF
            echo "   âœ… [MIT] $TITLE"
        fi
    done
fi
echo "   â†’ MIT TR: $MIT_COUNT æ¡"

# ========== 5. Dev.to ==========
echo ""
echo "ðŸ“¥ é‡‡é›† Dev.to..."
DEVTO_DATA=$(curl -s --connect-timeout 15 "https://dev.to/api/articles?tag=ai&per_page=5" 2>/dev/null)
DEVTO_COUNT=0

if [ -n "$DEVTO_DATA" ]; then
    for i in 0 1 2 3 4; do
        TITLE=$(echo "$DEVTO_DATA" | jq -r ".[$i].title // empty" 2>/dev/null)
        URL=$(echo "$DEVTO_DATA" | jq -r ".[$i].url // empty" 2>/dev/null)
        DESC=$(echo "$DEVTO_DATA" | jq -r ".[$i].description // empty" 2>/dev/null)
        REACTIONS=$(echo "$DEVTO_DATA" | jq -r ".[$i].positive_reactions_count // 0" 2>/dev/null)
        AUTHOR=$(echo "$DEVTO_DATA" | jq -r ".[$i].user.name // empty" 2>/dev/null)
        
        if [ -n "$TITLE" ] && [ -n "$URL" ]; then
            ((DEVTO_COUNT++))
            TOTAL_COUNT=$((TOTAL_COUNT + 1))
            TIMESTAMP=$(date +%s)
            FILENAME="DT_${REACTIONS}_${TIMESTAMP}_${i}.md"
            
            # æå–å†…å®¹
            CONTENT=$(extract_content "$URL")
            
            cat > "$OUTPUT_DIR/$FILENAME" << EOF
---
title: "$TITLE"
url: "$URL"
source: "Dev.to"
date: "$DATE"
score: "$REACTIONS"
author: "$AUTHOR"
---

# $TITLE

**æ¥æº**: [Dev.to]($URL) | **â¤ï¸ reactions**: $REACTIONS | **ä½œè€…**: $AUTHOR

## æ‘˜è¦

$DESC

## åŽŸæ–‡å†…å®¹

$CONTENT

---
*è‡ªåŠ¨é‡‡é›†äºŽ $DATE*
EOF
            echo "   âœ… [DT] $TITLE"
        fi
    done
fi
echo "   â†’ Dev.to: $DEVTO_COUNT æ¡"

echo ""
echo "============================================"
echo "ðŸ“Š é‡‡é›†å®Œæˆ! æ€»è®¡: $TOTAL_COUNT æ¡"
echo "   - HN: $HN_COUNT | GH: $GH_COUNT | HF: $HF_COUNT"
echo "   - MIT: $MIT_COUNT | DT: $DEVTO_COUNT"
echo "============================================"

echo ""
echo "âœ… å®Œæˆ! æ–‡ä»¶ä¿å­˜äºŽ: $OUTPUT_DIR/"
echo ""
echo "ðŸ”„ æäº¤åˆ° GitHub..."

# é…ç½® git ç”¨æˆ·ä¿¡æ¯ï¼ˆä½¿ç”¨ GitHub Actions botï¼‰
git config user.name "github-actions[bot]"
git config user.email "github-actions[bot]@users.noreply.github.com"

# ä½¿ç”¨ GITHUB_TOKEN è¿›è¡Œè®¤è¯
git add $OUTPUT_DIR/
git commit -m "AI Daily: $DATE - $TOTAL_COUNT æ¡å†…å®¹" || echo "æ— æ–°å†…å®¹"

# é…ç½®è¿œç¨‹ URL ä½¿ç”¨ token è®¤è¯
git remote set-url origin "https://x-access-token:${GITHUB_TOKEN}@github.com/xxl115/ai-daily-collector.git"
git push origin master || echo "æŽ¨é€å¤±è´¥"

echo ""
echo "âœ… å…¨éƒ¨å®Œæˆ!"
